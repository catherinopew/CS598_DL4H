{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlv6knX04FiY"
      },
      "source": [
        "# Mount Notebook to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfk8Zrul_E8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4414773-101d-4772-c9db-36a06eaa15b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "The paper our group has chosen is **SANSformers: Self-Supervised Forecasting in\n",
        "Electronic Health Records with\n",
        "Attention-Free Models.**\n",
        "\n",
        "* **Background:**\n",
        "  * **Problem:**\n",
        "    * This paper tackles three distinct prediction problems, however, two rely on the confidential Pummel dataset, so we will focus on the third problem: **mortality prediction with MIMIC data.**\n",
        "  * **Importance of Problem:**\n",
        "    * Accurate mortality prediction is important for many reasons including improving patient care, correctly allocating resources, and assisting in clinical decision making. Accurate mortality prediction helps to tailor treatment plans and focus resources on patients with higher mortality likelihood. Additionally, it can help medical staff to make life-saving decisions around intensity of care.\n",
        "  * **Difficulty of Problem:**\n",
        "    * One difficulty of mortality prediction relates to the data it relies upon, EHR data. EHR data is a natural language input from healthcare professionals, so the data accuracy relies on accurate input by busy healthcare professionals. Additionally, the unique structure and charateristics of EHR data, especially the sequences of clinical codes, present challenges for Transformers because the consecutive visits in an EHR dataset are not always strongly correlated.\n",
        "  * **State of the Art Methods and Effectiveness:** This paper compared results against 5 state of the art models. These models mainly relied on Transformers with attention mechanisms. Additionally, because of the complexity of prediction on EHR data, Lasso regression with complex feature engineering of EHR data has proven a comparable baseline.\n",
        "    * L1-reg Logistic Regression: Traditional Lasso regression method with feature engineering which proves comparable to complex Transformer methods on EHR data.\n",
        "      * Narges Razavian, Saul Blecker, Ann Marie Schmidt, Aaron Smith- McLallen, Somesh Nigam, and David Sontag. Population-level pre- diction of type 2 diabetes from claims data and analysis of risk factors. Big Data, 3(4):277–287, 2015.\n",
        "    * RETAIN: A Transformer approach using a \"reverse time attention mechanism\"\n",
        "      * Edward Choi, Mohammad Taha Bahadori, Joshua A Kulas, Andy Schuetz, Walter F Stewart, and Jimeng Sun. RETAIN: An interpretable predictive model for healthcare using reverse time attention mechanism. Advances in Neural Information Processing Systems, pages 3512–3520, 2016.\n",
        "    * BEHRT: Transformer architecture trained on\n",
        "      * Yikuan Li, Shishir Rao, Jose ́ Roberto Ayala Solares, Abdelaali Hassaine, Rema Ramakrishnan, Dexter Canoy, Yajie Zhu, Kazem Rahimi, and Gholamreza Salimi-Khorshidi. BEHRT: Transformer for electronic health records. Scientific Reports, 10(1):1–12, 2020.\n",
        "    * BRLTM: Bidirectional representation learning from transformers using multi- modal electronic health record data.\n",
        "      * Yiwen Meng, William Speier, Michael K Ong, and Corey W Arnold. Bidirectional representation learning from transformers using multi- modal electronic health record data to predict depression. IEEE Journal of Biomedical and Health Informatics, 25(8):3121–3129, 2021.\n",
        "    * SARD: \"Self Attention with Reverse Distillation employs a mix of contextual and temporal embedding along with self-attention mechanisms\" (page 3)\n",
        "      * Rohan Kodialam, Rebecca Boiarsky, Justin Lim, Aditya Sai, Neil Dixit, and David Sontag. Deep contextual clinical prediction with reverse distillation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 249–258, 2021.\n",
        "\n",
        "* **Paper Explanation:**\n",
        "  * **What did the paper propose?** This paper proposed a new architecture for healthcare prediction tasks with EHR data, the SANSformer architecture.\n",
        "  * **Innovations of the Method** The main innovations of this paper are the following:\n",
        "    * Removing Self-Attention Mechanism: this paper proposes sequential architecture for EHR analysis, eliminating the self-attention mechanism, which they hypothesize is too complex for EHR data.\n",
        "    * Generative Summary Pre-training: This paper borrows the pre-training strategy commonly used in NLP and computer vision tasks. This paper calls their approach Generative Summary Pre-training (GSP), where they predict summary statistics for a future window allowing for more reliable pretraining.\n",
        "    * Axial Decomposition: The SANSformers model leverages axial decomposition to better model interactions within intra-visit data.\n",
        "  * **How well does the method work?** On the MIMIC mortality task, both the Additive and Axial SANSformer models performed better than comparable methods on AUC over 5 runs. The means AUC scores for each of the 5 runs are reported below:\n",
        "    * L1-reg Logistic Regression: 0.728\n",
        "    * RETAIN: 0.707\n",
        "    * BEHRT: 0.693\n",
        "    * BRLTM: 0.695\n",
        "    * SARD: 0.742\n",
        "    * Additive SANSformer: 0.759\n",
        "    * Axial SANSformer: 0.761\n",
        "  * **What is the contribution of the research regime?** According to page 2 of the paper, the research regime claims the following contributions:\n",
        "    * They introduce SANSformers, a novel, attention-free sequential model specifically designed for EHR data, supplemented with inductive biases such as axial decomposition and ∆τ embeddings to cater to the unique challenges posed by the EHR domain.\n",
        "    * We conduct extensive comparisons of SANSformers with strong baseline models on two real-world EHR datasets. Our results highlight the superior data efficiency and prediction accuracy of our model compared to the existing baselines.\n",
        "    * We demonstrate the value of self-supervised pre-training on a larger population for predicting future healthcare utilization of smaller, distinct patient subgroups. We introduce Generative Summary Pre-training (GSP), a self- supervised pre-training objective for EHR data, predict- ing future summary statistics. This offers considerable potential in improving healthcare resource allocation predictions, an application of significant importance in healthcare management.\n",
        "    "
      ],
      "metadata": {
        "id": "OaXN_LIItzcJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "**Hypothesis:** Upon reproduction, the SANSformer model will outperform baselines in the MIMIC mortality prediction task, as claimed in the paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8Nlu2YfP_xw"
      },
      "source": [
        "![SANSformer Architecture](https://drive.google.com/uc?export=view&id=1kz4TGgcy2DNAeLn6r-LFDj7BgDfUsYj8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "# import  packages you need\n",
        "import re\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "TARGET_OFFSET = 2\n",
        "MIMIC_PATH = './drive/MyDrive/mimic-iv-1.0/'\n",
        "OUTPUT_PATH = MIMIC_PATH + 'output/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVUQS0CHry0"
      },
      "source": [
        "##  Data\n",
        "**Source of the Data:**\n",
        "  * The data utilized comes from the [MIMIC-IV v1.0](https://physionet.org/content/mimiciv/1.0/) dataset which contains electronic health records of around 250,000 patients. It features extensive patient data including vitals, doctor notes, diagnoses, procedures, and more. Our paper focuses soley on hospital admissions, extracting relevant information from patients, admissions, diagnoses ICD, procedures ICD, drgcodes, and service tables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "# dir and function to load raw data\n",
        "def load_raw_data(filename, raw_data_dir=MIMIC_PATH, compression='gzip', **kwargs):\n",
        "  # implement this function to load raw data to dataframe/numpy array/tensor\n",
        "  try:\n",
        "      filepath = raw_data_dir + filename\n",
        "      # Load the compressed CSV file\n",
        "      data = pd.read_csv(filepath, compression=compression, **kwargs)\n",
        "      print(f\"{filename} file loaded successfully.\")\n",
        "      return data\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# calculate statistics\n",
        "def calculate_stats(raw_data):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "  return raw_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX-878-GyOd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585aa002-5768-4e54-d3e3-74b550c8736f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "core/admissions.csv.gz file loaded successfully.\n",
            "core/patients.csv.gz file loaded successfully.\n",
            "hosp/diagnoses_icd.csv.gz file loaded successfully.\n",
            "hosp/procedures_icd.csv.gz file loaded successfully.\n",
            "hosp/drgcodes.csv.gz file loaded successfully.\n",
            "hosp/services.csv.gz file loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "admits = load_raw_data(\n",
        "    \"core/admissions.csv.gz\",\n",
        "    parse_dates=[\"admittime\", \"dischtime\"],\n",
        ")\n",
        "patients = load_raw_data('core/patients.csv.gz')\n",
        "diags = load_raw_data(\"hosp/diagnoses_icd.csv.gz\")\n",
        "procs = load_raw_data(\"hosp/procedures_icd.csv.gz\")\n",
        "drgs = load_raw_data(\"hosp/drgcodes.csv.gz\")\n",
        "services = load_raw_data(\"hosp/services.csv.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzptPOLqzKZ4"
      },
      "source": [
        "**Statistics**\n",
        "  * This is the dataset prior to being preprocessed.\n",
        "![Mimic Dataset](https://drive.google.com/uc?export=view&id=13z5ma7Rn-Dm_wYVAowHfRP0z3J-HN2Kf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYMtb6-TyDY8",
        "outputId": "d82a0f49-2071-4a36-aeff-4c0f66f5a50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient Statistics\n",
            "         subject_id     anchor_age    anchor_year\n",
            "count  3.822780e+05  382278.000000  382278.000000\n",
            "mean   1.500927e+07      40.931804    2150.844430\n",
            "std    2.885080e+06      26.114457      23.389475\n",
            "min    1.000002e+07       0.000000    2109.000000\n",
            "25%    1.251226e+07      22.000000    2131.000000\n",
            "50%    1.501350e+07      41.000000    2151.000000\n",
            "75%    1.750570e+07      62.000000    2171.000000\n",
            "max    1.999999e+07      91.000000    2208.000000 \n",
            "\n",
            "Diagnoses ICD Statistics\n",
            "         subject_id       hadm_id       seq_num   icd_version\n",
            "count  5.280351e+06  5.280351e+06  5.280351e+06  5.280351e+06\n",
            "mean   1.499741e+07  2.500180e+07  8.174094e+00  9.414742e+00\n",
            "std    2.878713e+06  2.888808e+06  6.515281e+00  4.926774e-01\n",
            "min    1.000002e+07  2.000002e+07  1.000000e+00  9.000000e+00\n",
            "25%    1.249952e+07  2.250008e+07  3.000000e+00  9.000000e+00\n",
            "50%    1.499722e+07  2.500333e+07  6.000000e+00  9.000000e+00\n",
            "75%    1.749305e+07  2.750520e+07  1.100000e+01  1.000000e+01\n",
            "max    1.999999e+07  2.999993e+07  3.900000e+01  1.000000e+01 \n",
            "\n",
            "Procedures ICD Statistics\n",
            "         subject_id       hadm_id        seq_num    icd_version\n",
            "count  7.796250e+05  7.796250e+05  779625.000000  779625.000000\n",
            "mean   1.499939e+07  2.501086e+07       3.140965       9.331683\n",
            "std    2.881459e+06  2.885438e+06       3.097216       0.470818\n",
            "min    1.000002e+07  2.000004e+07       1.000000       9.000000\n",
            "25%    1.250091e+07  2.252063e+07       1.000000       9.000000\n",
            "50%    1.499722e+07  2.501477e+07       2.000000       9.000000\n",
            "75%    1.749459e+07  2.751181e+07       4.000000      10.000000\n",
            "max    1.999999e+07  2.999983e+07      41.000000      10.000000 \n",
            "\n",
            "DRG Codes Statistics\n",
            "         subject_id       hadm_id       drg_code   drg_severity  drg_mortality\n",
            "count  7.696220e+05  7.696220e+05  769622.000000  374454.000000  374454.000000\n",
            "mean   1.500546e+07  2.500345e+07     457.865742       2.189959       1.829159\n",
            "std    2.881881e+06  2.889447e+06     265.732620       0.967268       0.987247\n",
            "min    1.000002e+07  2.000002e+07       1.000000       1.000000       1.000000\n",
            "25%    1.250997e+07  2.250262e+07     235.000000       1.000000       1.000000\n",
            "50%    1.500618e+07  2.500541e+07     424.000000       2.000000       1.000000\n",
            "75%    1.750453e+07  2.751026e+07     691.000000       3.000000       3.000000\n",
            "max    1.999999e+07  2.999983e+07     999.000000       4.000000       4.000000 \n",
            "\n",
            "Services Statistics\n",
            "         subject_id       hadm_id\n",
            "count  5.628920e+05  5.628920e+05\n",
            "mean   1.500303e+07  2.500373e+07\n",
            "std    2.879470e+06  2.888705e+06\n",
            "min    1.000002e+07  2.000002e+07\n",
            "25%    1.250978e+07  2.250321e+07\n",
            "50%    1.500485e+07  2.500813e+07\n",
            "75%    1.749252e+07  2.750580e+07\n",
            "max    1.999999e+07  2.999993e+07\n"
          ]
        }
      ],
      "source": [
        "print(\"Patient Statistics\")\n",
        "print(calculate_stats(patients), \"\\n\")\n",
        "print(\"Diagnoses ICD Statistics\")\n",
        "print(calculate_stats(diags), \"\\n\")\n",
        "print(\"Procedures ICD Statistics\")\n",
        "print(calculate_stats(procs), \"\\n\")\n",
        "print(\"DRG Codes Statistics\")\n",
        "print(calculate_stats(drgs), \"\\n\")\n",
        "print(\"Services Statistics\")\n",
        "print(calculate_stats(services))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONo6Skvr5SdZ"
      },
      "source": [
        "**Data Processing Overview:**\n",
        "\n",
        "The provided code encompasses a comprehensive data processing pipeline tailored for medical data. It includes several steps such as sampling data, merging datasets, handling missing values, preprocessing textual data (ICD codes, procedures, etc.), and encoding categorical features. Below are the key steps involved:\n",
        "\n",
        "1. **Sampling Data:**\n",
        "   - Randomly sample data from different sources (admissions, patients, diagnoses, procedures, DRGs, services) based on a specified percentage.\n",
        "\n",
        "2. **Merging Datasets:**\n",
        "   - Merge patient information with admission details.\n",
        "   - Calculate length of stay (LOS) for each patient and cap it at 180 days.\n",
        "   - Sort patient records based on admission and discharge time.\n",
        "   - Compute days since the previous admission and bin them into categories.\n",
        "\n",
        "3. **Processing Diagnosis, Procedure, DRG, and Service Codes:**\n",
        "   - Preprocess diagnosis, procedure, DRG, and service codes by extracting relevant information and grouping them by admission ID.\n",
        "   - Encode categorical features such as gender, language, and ethnicity.\n",
        "\n",
        "4. **Vectorization:**\n",
        "   - Vectorize textual data (ICD codes, procedures, DRGs, services, admission type, insurance, marital status) using a custom vectorizer.\n",
        "   - Encode categorical features and save the vectorizer for future use.\n",
        "\n",
        "5. **Data Splitting:**\n",
        "   - Split the processed data into training and testing sets using a specified ratio.\n",
        "\n",
        "6. **Saving Preprocessed Data:**\n",
        "   - Save the preprocessed data into Feather format files for later use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMK-EX6IfY8_"
      },
      "source": [
        "**Vocabulary and Sequence Vocabulary**\n",
        "  * These two classes provide functionality for token-to-index and index-to-token mappings, with the latter extending the former to include special tokens for sequence processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRVsgkzSj1Qb"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, token_to_idx=None):\n",
        "        if token_to_idx is None:\n",
        "            token_to_idx = {}\n",
        "        self.token_to_idx = token_to_idx\n",
        "\n",
        "        self.idx_to_token = {idx: token for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def add_token(self, token):\n",
        "        if token in self.token_to_idx:\n",
        "            index = self.token_to_idx[token]\n",
        "        else:\n",
        "            index = len(self.token_to_idx)\n",
        "            self.token_to_idx[token] = index\n",
        "            self.idx_to_token[index] = token\n",
        "        return index\n",
        "\n",
        "    def add_tokens(self, tokens):\n",
        "        return [self.add_token(token) for token in tokens]\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(f\"the index ({index}) is not in the Vocabulary\")\n",
        "        return self.idx_to_token[index]\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<{type(self).__name__}(size={len(self)})>\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)\n",
        "\n",
        "    def to_serializable(self):\n",
        "        return {\"token_to_idx\": self.token_to_idx}\n",
        "\n",
        "    @classmethod\n",
        "    def from_serializable(cls, contents):\n",
        "        return cls(**contents)\n",
        "\n",
        "\n",
        "class SequenceVocabulary(Vocabulary):\n",
        "    \"Wraps around Vocab to add start and end tokens\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        token_to_idx: dict = None,\n",
        "        unk_token: str = \"<unk>\",\n",
        "        begin_seq_token: str = \"<sos>\",\n",
        "        end_seq_token: str = \"<eos>\",\n",
        "        pad_token: str = \"<pad>\",\n",
        "    ):\n",
        "        super().__init__(token_to_idx)\n",
        "\n",
        "        self.unk_token = unk_token\n",
        "        self.pad_token = pad_token\n",
        "        self.begin_seq_token = begin_seq_token\n",
        "        self.end_seq_token = end_seq_token\n",
        "        self.mask_token = \"<mask>\"\n",
        "\n",
        "        self.pad_index = self.add_token(self.pad_token)  # pad token has index 0\n",
        "        self.mask_index = self.add_token(self.mask_token)  # mask token has index 1\n",
        "        self.unk_index = self.add_token(self.unk_token)  # unk has index 2\n",
        "        self.begin_seq_index = self.add_token(self.begin_seq_token)  # begin has index 3\n",
        "        self.end_seq_index = self.add_token(self.end_seq_token)  # end has index 4\n",
        "\n",
        "        self.idx_to_token = {idx: token for token, idx in self.token_to_idx.items()}\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx.get(token, self.unk_index)\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index ({index}) is not in the SequenceVocabulary\")\n",
        "        return self.idx_to_token[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blbXCh98fxp_"
      },
      "source": [
        "**EHRCountVectorizer**\n",
        "  * This class provides functionality to convert sequences of ICD10 codes into vectorized arrays, facilitating the transformation of patient history sequences into indexed representations based on a specified vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW-m1ey-j30s"
      },
      "outputs": [],
      "source": [
        "class EHRCountVectorizer:\n",
        "    \"\"\"\n",
        "    Vectorizer to convert a sequence of ICD10 code to vectorized arrays\n",
        "    In this specific instance, output is not a sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, seq_vocab: SequenceVocabulary):\n",
        "        self.seq_vocab = seq_vocab\n",
        "        self.seq_vocab_len = len(self.seq_vocab)\n",
        "\n",
        "    def vectorize(self, patient_history_seq: str, sep=\";\"):\n",
        "        \"\"\"\n",
        "        Convert the patient history sequence (diagnoses, procedures, etc) to a list of indeces based on the\n",
        "        vocabulary object.\n",
        "        This method also handles the padding of the \"inner-list\", i.e.,\n",
        "        the number of diagnoses per visit. Padding the number of visits sequence\n",
        "        is handled by the collate function in trainer.\n",
        "        Args:\n",
        "          diagnoses: String of diagnoses for a patient, each visit\n",
        "                     separated by ';', diagnoses per\n",
        "                     visit separated by space\n",
        "        Returns:\n",
        "          vectorized_history: list of vectorized visit codes\n",
        "          n_tkns_per_visit: list of number of tokens per visit\n",
        "        \"\"\"\n",
        "        # split\n",
        "        visits = [visit for visit in patient_history_seq.split(sep)]\n",
        "        n_tkns_per_visit = [\n",
        "            len(visit.split(\" \")) for visit in patient_history_seq.split(sep)\n",
        "        ]\n",
        "\n",
        "        vectorized_history = []\n",
        "        max_visit_items = 0\n",
        "        for visit in visits:\n",
        "            items_per_visit_i = [\n",
        "                self.seq_vocab.lookup_token(token) for token in visit.split(\" \")\n",
        "            ]\n",
        "            items_per_visit_i_length = len(items_per_visit_i)\n",
        "\n",
        "            if max_visit_items < items_per_visit_i_length:\n",
        "                max_visit_items = items_per_visit_i_length\n",
        "            vectorized_history.append(items_per_visit_i)\n",
        "\n",
        "        return vectorized_history, n_tkns_per_visit\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe_cols(cls, df, col_names):\n",
        "        seq_vocab = SequenceVocabulary()\n",
        "        for colname in col_names:\n",
        "            df[colname] = df[colname].apply(\n",
        "                lambda row: row.replace(\";\", \" \").split(\" \")\n",
        "            )\n",
        "            seq_vocab.add_tokens(np.concatenate(df[colname].values))\n",
        "        print(f\"Corpus has {len(seq_vocab)} unique tokens\")\n",
        "        return cls(seq_vocab)\n",
        "\n",
        "    @classmethod\n",
        "    def from_dataframe(cls, df, colname=\"icd10\"):\n",
        "        seq_vocab = SequenceVocabulary()\n",
        "        df[colname] = df[colname].apply(lambda row: row.replace(\";\", \" \").split(\" \"))\n",
        "        seq_vocab.add_tokens(np.concatenate(df[colname].values))\n",
        "\n",
        "        print(f\"Corpus has {len(seq_vocab)} unique tokens\")\n",
        "        return cls(seq_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EN37rFkgPIX"
      },
      "source": [
        "**Data Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdMdnlihx7tm"
      },
      "outputs": [],
      "source": [
        "# process raw data\n",
        "def process_data(admits, patients, diags, procs, drgs, services, sample_percentage=0.3):\n",
        "\n",
        "  admits_sample_size = int(len(admits) * sample_percentage)\n",
        "  patients_sample_size = int(len(patients) * sample_percentage)\n",
        "  diags_sample_size = int(len(diags) * sample_percentage)\n",
        "  procs_sample_size = int(len(procs) * sample_percentage)\n",
        "  drgs_sample_size = int(len(drgs) * sample_percentage)\n",
        "  services_sample_size = int(len(services) * sample_percentage)\n",
        "\n",
        "  admits = admits.sample(n=admits_sample_size, random_state=42)\n",
        "  patients = patients.sample(n=patients_sample_size, random_state=42)\n",
        "  diags = diags.sample(n=diags_sample_size, random_state=42)\n",
        "  procs = procs.sample(n=procs_sample_size, random_state=42)\n",
        "  drgs = drgs.sample(n=drgs_sample_size, random_state=42)\n",
        "  services = services.sample(n=services_sample_size, random_state=42)\n",
        "\n",
        "  # implement this function to process the data as you need\n",
        "  patients = patients.merge(admits, on=\"subject_id\", how=\"right\")\n",
        "  patients[\"los\"] = patients[\"dischtime\"] - patients[\"admittime\"]\n",
        "  patients[\"los\"] = patients[\"los\"].dt.total_seconds() / 86400.0\n",
        "  # topcap los at 180 days\n",
        "  patients[\"los\"] = np.clip(patients[\"los\"], 0, 180)\n",
        "  patients.drop(\n",
        "      [\n",
        "          \"discharge_location\",\n",
        "          \"anchor_year_group\",\n",
        "          \"anchor_year\",\n",
        "          \"admission_location\",\n",
        "          \"discharge_location\",\n",
        "          \"edregtime\",\n",
        "          \"edouttime\",\n",
        "      ],\n",
        "      axis=1,\n",
        "      inplace=True,\n",
        "  )\n",
        "  patients.sort_values([\"subject_id\", \"admittime\", \"dischtime\"], inplace=True)\n",
        "  patients[\"days_from_prev\"] = patients[\"admittime\"] - patients[\"admittime\"].shift(1)\n",
        "  patients[\"days_from_prev\"] = patients[\"days_from_prev\"].dt.total_seconds() / 86400.0\n",
        "  bin_edges = np.arange(0, np.max(patients[\"days_from_prev\"]) + 16, 15)\n",
        "  patients[\"days_from_prev\"] = np.digitize(patients[\"days_from_prev\"].values, bin_edges)\n",
        "\n",
        "  # store the last recorded hospital_expire_flag as the flag for the patient\n",
        "  patients = patients.drop(\"hospital_expire_flag\", axis=1).join(\n",
        "      patients.groupby(\"subject_id\")[[\"subject_id\", \"hospital_expire_flag\"]]\n",
        "      .tail(1)\n",
        "      .set_index(\"subject_id\"),\n",
        "      on=\"subject_id\",\n",
        "      how=\"inner\",\n",
        "  )\n",
        "\n",
        "  # drop last visits for each patient\n",
        "  hadm_to_drop = (\n",
        "      patients.groupby(\"subject_id\")[[\"dischtime\", \"hadm_id\"]].tail(TARGET_OFFSET).hadm_id\n",
        "  )\n",
        "  patients = patients[~patients[\"hadm_id\"].isin(hadm_to_drop)]\n",
        "\n",
        "  # processing diagnosis codes\n",
        "  # diags = diags.reset_index()\n",
        "  diags[\"icd_code\"] = diags[\"icd_code\"].apply(lambda row: row[:3])\n",
        "  diags[\"icd_version\"] = diags[\"icd_version\"].apply(lambda row: f\"IP{row}_\")\n",
        "  diags[\"icd_all\"] = diags[\"icd_version\"] + diags[\"icd_code\"]\n",
        "  print(diags.head())\n",
        "\n",
        "  # group diag codes according to admission id\n",
        "  n_unique_admid = diags.hadm_id.nunique()\n",
        "  diags.set_index(\"hadm_id\", inplace=True)\n",
        "  diag_cols = [\"subject_id\", \"hadm_id\", \"icd_all\"]\n",
        "  grouped_dict = {k: [] for k in diag_cols}\n",
        "\n",
        "  for g, f in tqdm(diags.groupby(diags.index), total=n_unique_admid):\n",
        "      grouped_dict[\"hadm_id\"].append(g)\n",
        "      grouped_dict[\"subject_id\"].append(f.subject_id.values[0])\n",
        "      for col in diag_cols:\n",
        "          if col not in [\"hadm_id\", \"subject_id\"]:\n",
        "              grouped_dict[col].append(\" \".join(f[col].values))\n",
        "\n",
        "  grouped_diag = pd.DataFrame(grouped_dict)\n",
        "  print(grouped_diag.head())\n",
        "  grouped_diag.to_feather(OUTPUT_PATH + \"grouped_diag.feather\")\n",
        "\n",
        "  # processing procedure codes\n",
        "  # procs = procs.reset_index()\n",
        "  procs[\"icd_code\"] = procs[\"icd_code\"].apply(lambda row: row[:3])\n",
        "  procs[\"icd_version\"] = procs[\"icd_version\"].apply(lambda row: f\"IP{row}_\")\n",
        "  procs[\"icd_all\"] = procs[\"icd_version\"] + procs[\"icd_code\"]\n",
        "  print(procs.head())\n",
        "\n",
        "  # group proc codes according to admit id\n",
        "  n_unique_admid = procs.hadm_id.nunique()\n",
        "  procs.set_index(\"hadm_id\", inplace=True)\n",
        "  diag_cols = [\"subject_id\", \"hadm_id\", \"icd_all\"]\n",
        "  grouped_dict = {k: [] for k in diag_cols}\n",
        "\n",
        "  for g, f in tqdm(procs.groupby(procs.index), total=n_unique_admid):\n",
        "      grouped_dict[\"hadm_id\"].append(g)\n",
        "      grouped_dict[\"subject_id\"].append(f.subject_id.values[0])\n",
        "      for col in diag_cols:\n",
        "          if col not in [\"hadm_id\", \"subject_id\"]:\n",
        "              grouped_dict[col].append(\" \".join(f[col].values))\n",
        "\n",
        "  grouped_proc = pd.DataFrame(grouped_dict)\n",
        "  grouped_proc.columns = [\"subject_id\", \"hadm_id\", \"proc_all\"]\n",
        "  print(grouped_proc.head())\n",
        "  grouped_proc.to_feather(OUTPUT_PATH + \"grouped_proc.feather\")\n",
        "\n",
        "  # process drg codes\n",
        "  drgs.drop(\n",
        "      [\"drg_type\", \"description\", \"drg_severity\", \"drg_mortality\"], axis=1, inplace=True\n",
        "  )\n",
        "  drgs[\"drg_code\"] = drgs[\"drg_code\"].astype(str)\n",
        "  print(drgs.head())\n",
        "\n",
        "  n_unique_admid = drgs.hadm_id.nunique()\n",
        "  drgs.set_index(\"hadm_id\", inplace=True)\n",
        "  diag_cols = [\"subject_id\", \"hadm_id\", \"drg_code\"]\n",
        "  grouped_dict = {k: [] for k in diag_cols}\n",
        "\n",
        "  for g, f in tqdm(drgs.groupby(drgs.index), total=n_unique_admid):\n",
        "      grouped_dict[\"hadm_id\"].append(g)\n",
        "      grouped_dict[\"subject_id\"].append(f.subject_id.values[0])\n",
        "      for col in diag_cols:\n",
        "          if col not in [\"hadm_id\", \"subject_id\"]:\n",
        "              grouped_dict[col].append(\" \".join(f[col].values))\n",
        "\n",
        "  grouped_drg = pd.DataFrame(grouped_dict)\n",
        "  grouped_drg.columns = [\"subject_id\", \"hadm_id\", \"drug_all\"]\n",
        "  print(grouped_drg.head())\n",
        "  grouped_drg.to_feather(OUTPUT_PATH + \"grouped_drg.feather\")\n",
        "\n",
        "  # process services\n",
        "  services.drop([\"transfertime\", \"prev_service\"], axis=1, inplace=True)\n",
        "  print(services.head())\n",
        "\n",
        "  n_unique_admid = services.hadm_id.nunique()\n",
        "  services.set_index(\"hadm_id\", inplace=True)\n",
        "  diag_cols = [\"subject_id\", \"hadm_id\", \"curr_service\"]\n",
        "  grouped_dict = {k: [] for k in diag_cols}\n",
        "\n",
        "  for g, f in tqdm(services.groupby(services.index), total=n_unique_admid):\n",
        "      grouped_dict[\"hadm_id\"].append(g)\n",
        "      grouped_dict[\"subject_id\"].append(f.subject_id.values[0])\n",
        "      for col in diag_cols:\n",
        "          if col not in [\"hadm_id\", \"subject_id\"]:\n",
        "              grouped_dict[col].append(\" \".join(f[col].values))\n",
        "\n",
        "  grouped_service = pd.DataFrame(grouped_dict)\n",
        "  grouped_service.columns = [\"subject_id\", \"hadm_id\", \"service_all\"]\n",
        "  print(grouped_service.head())\n",
        "  grouped_service.to_feather(OUTPUT_PATH + \"grouped_service.feather\")\n",
        "\n",
        "  # merging everything together\n",
        "  patients = patients.merge(grouped_diag, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
        "  patients = patients.merge(grouped_proc, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
        "  patients = patients.merge(grouped_drg, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
        "  patients = patients.merge(grouped_service, on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
        "\n",
        "  # handle missing rows\n",
        "  for col in patients.columns:\n",
        "      patients[col].fillna(\"missing\", inplace=True)\n",
        "\n",
        "  patients.reset_index(inplace=True)\n",
        "  n_unique_patid = patients.subject_id.nunique()\n",
        "  patients.set_index(\"subject_id\", inplace=True)\n",
        "  pat_cols = patients.columns.tolist() + [\"subject_id\"]\n",
        "  for col in patients.columns:\n",
        "      patients[col] = patients[col].astype(str)\n",
        "  grouped_dict = {k: [] for k in pat_cols}\n",
        "\n",
        "  for g, f in tqdm(patients.groupby(patients.index), total=n_unique_patid):\n",
        "      grouped_dict[\"subject_id\"].append(g)\n",
        "      for col in pat_cols:\n",
        "          if col not in [\"subject_id\"]:\n",
        "              grouped_dict[col].append(\";\".join(f[col].values))\n",
        "\n",
        "  grouped_patient = pd.DataFrame(grouped_dict)\n",
        "  grouped_patient[\"days_from_prev\"] = grouped_patient[\"days_from_prev\"].apply(\n",
        "      lambda row: \";\".join([\"0.0\"] + row.split(\";\")[1:])\n",
        "  )\n",
        "  num_cols = [\n",
        "      \"gender\",\n",
        "      \"anchor_age\",\n",
        "      \"dod\",\n",
        "      \"deathtime\",\n",
        "      \"language\",\n",
        "      \"ethnicity\",\n",
        "      \"hospital_expire_flag\",\n",
        "  ]\n",
        "  for col in num_cols:\n",
        "      grouped_patient[col] = grouped_patient[col].apply(lambda row: row.split(\";\")[-1])\n",
        "  print(grouped_patient.hospital_expire_flag.value_counts())\n",
        "  print(grouped_patient.head())\n",
        "  grouped_patient.to_feather(OUTPUT_PATH + f\"grouped_patient_rem{TARGET_OFFSET}.feather\")\n",
        "\n",
        "  #%%\n",
        "  mimic_df = pd.read_feather(OUTPUT_PATH + f\"grouped_patient_rem{TARGET_OFFSET}.feather\")\n",
        "  # %%\n",
        "  mimic_df[\"seq_length\"] = mimic_df[\"hadm_id\"].apply(lambda row: len(row.split(\";\")))\n",
        "\n",
        "\n",
        "  def remove_puncts(code):\n",
        "      return re.sub(\"[^A-Za-z<>]+\", \"\", code)\n",
        "\n",
        "\n",
        "  # encode speciality\n",
        "  all_gender = []\n",
        "  for idx in mimic_df.index:\n",
        "      all_gender += mimic_df.loc[idx, \"gender\"].split(\";\")\n",
        "\n",
        "  all_gender = set(all_gender)\n",
        "  le_gen = {ch: i for i, ch in enumerate(all_gender)}\n",
        "\n",
        "  # encode lang\n",
        "  all_lang = []\n",
        "  for idx in mimic_df.index:\n",
        "      all_lang += mimic_df.loc[idx, \"language\"].split(\";\")\n",
        "\n",
        "  all_lang = set(all_lang)\n",
        "  le_lang = {ch: i for i, ch in enumerate(all_lang)}\n",
        "\n",
        "  # encode ethn\n",
        "  all_ethn = []\n",
        "  for idx in mimic_df.index:\n",
        "      all_ethn += mimic_df.loc[idx, \"ethnicity\"].split(\";\")\n",
        "\n",
        "  all_ethn = set(all_ethn)\n",
        "  le_ethn = {ch: i for i, ch in enumerate(all_ethn)}\n",
        "\n",
        "  #%%\n",
        "\n",
        "\n",
        "  print(\"Creating vectorizers...\")\n",
        "\n",
        "  import sys\n",
        "\n",
        "  sys.path.append(\"../src/\")\n",
        "  # from dataset.vectorizer import EHRCountVectorizer\n",
        "  import pickle\n",
        "  import os\n",
        "\n",
        "  vectorizer = EHRCountVectorizer.from_dataframe_cols(mimic_df, ['icd_all', 'proc_all', 'drug_all', 'service_all', 'admission_type', 'insurance', 'marital_status'])\n",
        "\n",
        "  vec_dict = {\"mimic_all\": vectorizer}\n",
        "\n",
        "  with open(os.path.join(MIMIC_PATH, 'vectorizer.pickle'), 'wb') as handle:\n",
        "    pickle.dump(vec_dict, handle)\n",
        "\n",
        "\n",
        "  '''\n",
        "  def apply_prefix(row, prefix):\n",
        "      visits = row.split(\";\")\n",
        "      out_visits = []\n",
        "      for visit in visits:\n",
        "          out_visits.append(\" \".join([prefix + tok for tok in visit.split()]))\n",
        "      return \";\".join(out_visits)\n",
        "\n",
        "\n",
        "  mimic_df[\"icd_all\"] = mimic_df[\"icd_all\"].apply(lambda row: apply_prefix(row, \"diag\"))\n",
        "  mimic_df[\"proc_all\"] = mimic_df[\"proc_all\"].apply(lambda row: apply_prefix(row, \"proc\"))\n",
        "  mimic_df[\"drug_all\"] = mimic_df[\"drug_all\"].apply(lambda row: apply_prefix(row, \"drg\"))\n",
        "  mimic_df[\"admission_type\"] = mimic_df[\"admission_type\"].apply(\n",
        "      lambda row: apply_prefix(row, \"admtype\")\n",
        "  )\n",
        "  mimic_df[\"insurance\"] = mimic_df[\"insurance\"].apply(\n",
        "      lambda row: apply_prefix(row, \"insur\")\n",
        "  )\n",
        "  mimic_df[\"marital_status\"] = mimic_df[\"marital_status\"].apply(\n",
        "      lambda row: apply_prefix(row, \"marit\")\n",
        "  )\n",
        "  mimic_df[\"service_all\"] = mimic_df[\"service_all\"].apply(\n",
        "      lambda row: apply_prefix(row, \"serv\")\n",
        "  )\n",
        "  #%%\n",
        "  #%%\n",
        "  mimic_df[\"encoded_gender\"] = mimic_df[\"gender\"].apply(\n",
        "      lambda row: le_gen[row.split(\";\")[0]]\n",
        "  )\n",
        "  mimic_df[\"encoded_ethnicity\"] = mimic_df[\"ethnicity\"].apply(\n",
        "      lambda row: le_ethn[row.split(\";\")[0]]\n",
        "  )\n",
        "  mimic_df[\"encoded_language\"] = mimic_df[\"language\"].apply(\n",
        "      lambda row: le_lang[row.split(\";\")[0]]\n",
        "  )\n",
        "  #%%\n",
        "  '''\n",
        "  train, test = train_test_split(mimic_df, test_size=0.2, random_state=100)\n",
        "  train.reset_index(drop=True).to_feather(\n",
        "      OUTPUT_PATH + f\"mimic_train_rem{TARGET_OFFSET}.feather\"\n",
        "  )\n",
        "  test.reset_index(drop=True).to_feather(\n",
        "      OUTPUT_PATH + f\"mimic_test_rem{TARGET_OFFSET}.feather\"\n",
        "  )\n",
        "\n",
        "  print('Preprocessing successfully run')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQkog9fj5S6-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "64e057af44e046609cb09790419248c4",
            "b51bf74fc2a74e2b84126c9509b1a22d",
            "7948725cd9d040b9bda6e89408c1ad00",
            "067346f6ad584f82a109f8c5665c1b92",
            "5cf2d7ec6ab840ebad3e577c13334cd5",
            "d113e9e39de74bb39d0de1514e533277",
            "4accf68eb03542a88fba1146c06b20b4",
            "2ce203165eec497eb8269d11780ea1ab",
            "f5fb89f8d731470aafdc3ff0e9e792d6",
            "44bb66177bf94d82b55efb12a008c2b3",
            "5e6f39f20c2a495e972205666bc9e548",
            "846a30cb7f23402fa724c24b2189c402",
            "88cb8b19156c4c378f47da211f2d23f3",
            "d39f121641c64af79e5cb27757d7d5b5",
            "28a40763bcb84a3fa6c507520c40e72c",
            "356726fe5802402487e8c7ead670b8bd",
            "44b3324c17eb47a58c27b7cf7b792b6f",
            "38784163c32f4f9482dca580424d6866",
            "c2ec3204f33d4f01bacb05ce4da77730",
            "686a07c81a2b4966825679b4c57f9f63",
            "27a848be062842a98b509b9fdc283562",
            "c9e7e4ca8e0d4d80b7d5908ee2f36d4d",
            "7a087633887b4e63aaf63a6e5529a56e",
            "5dcdbc6f610c4e7889cd4b7ec824c272",
            "09f6da86b76a4cde863889cce65220f3",
            "39845296b6bb47af9a95befe5f9218b8",
            "0eb5d30431a24cddb49b11bdcd2bcb1e",
            "847af178dae4485d8e76f99ac4b681aa",
            "f1dc613adae44afd9f0b0ac739dc5fb8",
            "229712339d644ddfb6d4b5b5e4da46a7",
            "27418d8a0ec844868c7d4e63f251cabd",
            "aa1cfa586a5b488c8819484f13b62f5b",
            "e1a7bbe543a74fbc94df21d4fb9dae50",
            "c964093ec0434f3db65043939bc9a152",
            "b1db7f588a2145d088c093426a13cbda",
            "ccf976d0fd9345649cd1d860dd6fb570",
            "490a6098099d4ce1a59e0a128ba82181",
            "c7fe6600b2a64d0db611029b2bf40d45",
            "03803fbfbea549db8f2e353cee146751",
            "788c5177416c424692b4905e36c5ec3c",
            "2add81473a3744b3b6d7c4dd50700dff",
            "6e02f4b8bfa04b9a91a6bb6ce04aea3f",
            "5218d9bc89634e979f96fb128052a2af",
            "3b6a680bf5054c9ea39e068f9ccb0132",
            "cc9428ac629f4de0ac6c5a0cf3f5f1c5",
            "a78d2da600c84d88bcce3e437b9c7144",
            "0ed75e1301664f01bba7627a21a8112a",
            "69169a172b6e4729aab4aedce6ac589c",
            "c8c115d4844144fd8ad5c6f3a67a3081",
            "02103f42edfd4ef1875b442a7a20e88d",
            "0cd05ddbbb7e4434b8413b9975e0ba29",
            "00a9a5bd0d2341c88106fd92ff1560e2",
            "76388ba2432e440594ac907d3849ccbe",
            "f032b847bc3a4109b3f3cd3937da6c15",
            "104eefed747940e8b99d193f0ada60a3"
          ]
        },
        "outputId": "49266866-0851-43d0-821e-f5004bbf3271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         subject_id   hadm_id  seq_num icd_code icd_version  icd_all\n",
            "1900644    16407393  28720503        3      253        IP9_  IP9_253\n",
            "1470681    16310613  22511564        3      770        IP9_  IP9_770\n",
            "14671      17111314  24695806        2      510        IP9_  IP9_510\n",
            "2540175    10996799  27194950        7      311        IP9_  IP9_311\n",
            "2747090    14873105  26584177        5      288        IP9_  IP9_288\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/449784 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e057af44e046609cb09790419248c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   subject_id   hadm_id                                            icd_all\n",
            "0    10467237  20000019                    IP9_V16 IP9_038 IP9_493 IP9_272\n",
            "1    16925328  20000024  IP10_Z91 IP10_Y92 IP10_M81 IP10_K52 IP10_T47 I...\n",
            "2    19430048  20000034  IP10_E83 IP10_E43 IP10_F09 IP10_R10 IP10_R27 I...\n",
            "3    18910522  20000041                                    IP9_V10 IP9_278\n",
            "4    11146739  20000057  IP9_493 IP9_724 IP9_788 IP9_719 IP9_465 IP9_E8...\n",
            "        subject_id   hadm_id  seq_num   chartdate icd_code icd_version  \\\n",
            "79375     19271229  26960026        1  2147-12-28      3E0       IP10_   \n",
            "178364    19669225  22116871        6  2182-09-20      0TJ       IP10_   \n",
            "286972    19042464  29078128        1  2162-10-17      4B0       IP10_   \n",
            "290418    11581195  28782408        7  2189-05-18      B21       IP10_   \n",
            "677677    16374106  28744603        7  2152-01-04      0BH       IP10_   \n",
            "\n",
            "         icd_all  \n",
            "79375   IP10_3E0  \n",
            "178364  IP10_0TJ  \n",
            "286972  IP10_4B0  \n",
            "290418  IP10_B21  \n",
            "677677  IP10_0BH  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/148327 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "846a30cb7f23402fa724c24b2189c402"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   subject_id   hadm_id           proc_all\n",
            "0    18910522  20000041            IP9_815\n",
            "1    14546051  20000069           IP10_10E\n",
            "2    14990224  20000147  IP10_021 IP10_021\n",
            "3    12868349  20000164            IP9_845\n",
            "4    11755976  20000188           IP10_0VT\n",
            "        subject_id   hadm_id drg_code\n",
            "10956     16988043  21941101      641\n",
            "471499    18970138  27525882      304\n",
            "138313    16415605  21589154      152\n",
            "751092    12793992  29405120        4\n",
            "617856    11309329  23560349      194\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/197162 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a087633887b4e63aaf63a6e5529a56e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   subject_id   hadm_id drug_all\n",
            "0    16925328  20000024      663\n",
            "1    14046553  20000094  194 291\n",
            "2    19932294  20000095  795 640\n",
            "3    13074106  20000102  775 560\n",
            "4    11755976  20000188      795\n",
            "        subject_id   hadm_id curr_service\n",
            "412065    17612772  21185143          MED\n",
            "32959     19888603  24352165           NB\n",
            "289007    10157674  20023715          MED\n",
            "91010     16643077  20554697           NB\n",
            "401596    18446988  29689641          MED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/164844 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c964093ec0434f3db65043939bc9a152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   subject_id   hadm_id service_all\n",
            "0    18910522  20000041       ORTHO\n",
            "1    19932294  20000095          NB\n",
            "2    14990224  20000147        CMED\n",
            "3    13758099  20000239        CMED\n",
            "4    13267456  20000343         MED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/9978 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc9428ac629f4de0ac6c5a0cf3f5f1c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hospital_expire_flag\n",
            "0    9507\n",
            "1     471\n",
            "Name: count, dtype: int64\n",
            "  index   gender anchor_age         dod            hadm_id  \\\n",
            "0   0;1  missing    missing     missing  28301173;25282382   \n",
            "1     2        M       57.0     missing           26115941   \n",
            "2     3  missing    missing     missing           28755331   \n",
            "3     4        M       82.0  2144-06-18           26164209   \n",
            "4     5  missing    missing     missing           23517634   \n",
            "\n",
            "                                 admittime  \\\n",
            "0  2197-04-08 19:37:00;2197-04-17 02:01:00   \n",
            "1                      2145-01-04 19:56:00   \n",
            "2                      2131-01-23 21:30:00   \n",
            "3                      2143-02-05 17:52:00   \n",
            "4                      2159-03-14 20:02:00   \n",
            "\n",
            "                                 dischtime deathtime         admission_type  \\\n",
            "0  2197-04-15 12:01:00;2197-04-17 09:48:00   missing  URGENT;EU OBSERVATION   \n",
            "1                      2145-01-06 20:00:00   missing                 URGENT   \n",
            "2                      2131-01-26 17:40:00   missing         EU OBSERVATION   \n",
            "3                      2143-02-06 17:54:00   missing               EW EMER.   \n",
            "4                      2159-03-22 14:00:00   missing      OBSERVATION ADMIT   \n",
            "\n",
            "           insurance  ... marital_status               ethnicity  \\\n",
            "0  Medicare;Medicare  ...  SINGLE;SINGLE  BLACK/AFRICAN AMERICAN   \n",
            "1           Medicaid  ...       DIVORCED                   OTHER   \n",
            "2           Medicare  ...         SINGLE                   WHITE   \n",
            "3           Medicare  ...        MARRIED                   WHITE   \n",
            "4              Other  ...        WIDOWED                   WHITE   \n",
            "\n",
            "                                     los days_from_prev hospital_expire_flag  \\\n",
            "0  6.683333333333334;0.32430555555555557          0.0;1                    0   \n",
            "1                     2.0027777777777778            0.0                    0   \n",
            "2                     2.8402777777777777            0.0                    0   \n",
            "3                     1.0013888888888889            0.0                    0   \n",
            "4                      7.748611111111111            0.0                    0   \n",
            "\n",
            "                                             icd_all         proc_all  \\\n",
            "0    IP9_292 IP9_305 IP9_V08 IP9_305;IP9_780 IP9_070  missing;missing   \n",
            "1                                    IP9_564 IP9_401          IP9_488   \n",
            "2                    IP9_E84 IP9_780 IP9_V58 IP9_789          missing   \n",
            "3  IP9_196 IP9_414 IP9_V15 IP9_V15 IP9_V10 IP9_V1...          missing   \n",
            "4  IP10_D50 IP10_T40 IP10_F05 IP10_I73 IP10_N39 I...          missing   \n",
            "\n",
            "          drug_all    service_all subject_id  \n",
            "0  missing;missing  PSYCH;missing   10002930  \n",
            "1          missing        missing   10003637  \n",
            "2          missing        missing   10004322  \n",
            "3          missing            MED   10004401  \n",
            "4              463            MED   10004606  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Creating vectorizers...\n",
            "Corpus has 2668 unique tokens\n",
            "Preprocessing successfully run\n"
          ]
        }
      ],
      "source": [
        "processed_data = process_data(admits, patients, diags, procs, drgs, services)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8IVWGv7gxPq"
      },
      "source": [
        "**Attention Blocks**\n",
        "  * This code block implements components for a small-scale transformer architecture, including a simplified attention mechanism, SmallAttention, a layer with multi-layer perceptron units, FullMLPLayer, and a transformer layer, SansformerLayer, with layer normalization and dropout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOaoGXAYPfTU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.fft\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SmallAttention(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, dim_inner, causal=False):\n",
        "        super().__init__()\n",
        "        self.scale = dim_inner ** -0.5\n",
        "        self.causal = causal\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim_in, dim_inner * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim_inner, dim_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        q, k, v = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        sim = torch.einsum(\"b i d, b j d -> b i j\", q, k) * self.scale\n",
        "\n",
        "        if self.causal:\n",
        "            mask = torch.ones(sim.shape[-2:], device=device).triu(1).bool()\n",
        "            sim.masked_fill_(mask[None, ...], -torch.finfo(q.dtype).max)\n",
        "\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = torch.einsum(\"b i j, b j d -> b i d\", attn, v)\n",
        "        return self.to_out(out)\n",
        "\n",
        "\n",
        "class FullMLPLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self, d_model, max_seq_len, causal, act=nn.GELU(), ff_hidden_mult=4, p_do=0.8\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        dim = int(d_model * ff_hidden_mult)\n",
        "        dim_out = dim // 2\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.causal = causal\n",
        "        self.do = nn.Dropout(p_do)\n",
        "\n",
        "        self.proj_ch1 = nn.Sequential(nn.Linear(d_model, dim), nn.GELU())\n",
        "        self.conv_proj = nn.Conv1d(max_seq_len, max_seq_len, 1)\n",
        "\n",
        "        self.proj_out = nn.Linear(dim // 2, d_model)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(dim_out)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.act = act\n",
        "        # optional small attention improves accuracy\n",
        "        # self.attn = SmallAttention(d_model, dim // 2, 64, causal)\n",
        "\n",
        "        init_eps = 1e-3\n",
        "        init_eps /= max_seq_len\n",
        "        nn.init.uniform_(self.conv_proj.weight, -init_eps, init_eps)\n",
        "        nn.init.constant_(self.conv_proj.bias, 1.0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        visit_len = x.size(1)\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.act(self.proj_ch1(x))\n",
        "\n",
        "        x_attn = None\n",
        "        # x_attn = self.attn(shortcut)\n",
        "\n",
        "        # spatial proj unit\n",
        "        res, gate = x.chunk(2, dim=-1)\n",
        "        gate = self.norm2(gate)\n",
        "\n",
        "        weight, bias = self.conv_proj.weight, self.conv_proj.bias\n",
        "        weight, bias = weight[:visit_len, :visit_len], bias[:visit_len]\n",
        "        if self.causal:\n",
        "            mask = torch.ones(weight.shape[:2], device=x.device).triu_(1).bool()\n",
        "            weight = weight.masked_fill(mask[..., None], 0.0)\n",
        "\n",
        "        gate = F.conv1d(gate, weight, bias)\n",
        "\n",
        "        # x = gate * res\n",
        "        if x_attn is not None:\n",
        "            x = (gate + x_attn) * res\n",
        "        else:\n",
        "            x = gate * res\n",
        "\n",
        "        x = self.proj_out(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class SansformerLayer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model,\n",
        "        causal,\n",
        "        ff_hidden_mult=4,\n",
        "        p_do=0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sans_attention = FullMLPLayer(\n",
        "            d_model=d_model,\n",
        "            max_seq_len=200,\n",
        "            causal=causal,\n",
        "            ff_hidden_mult=ff_hidden_mult,\n",
        "            p_do=p_do,\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # GEGLU improves perf but is param heavy\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, ff_hidden_mult * d_model),\n",
        "            nn.GELU(),\n",
        "            # GEGLU(ff_hidden_mult * d_model, ff_hidden_mult * d_model),\n",
        "            nn.Dropout(p_do),\n",
        "            nn.Linear(ff_hidden_mult * d_model, d_model),\n",
        "            nn.Dropout(p_do),\n",
        "        )\n",
        "        self.do = nn.Dropout(p_do)\n",
        "\n",
        "    def forward(self, x, length_mask=None):\n",
        "        sans_attended = self.sans_attention(x)\n",
        "        y = x = self.norm1(sans_attended)\n",
        "        y = self.ff(y)\n",
        "        return self.norm2(x + y)\n",
        "\n",
        "\n",
        "###########\n",
        "# Helpers\n",
        "class Conv1D(nn.Module):\n",
        "    \"\"\"\n",
        "    1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).\n",
        "\n",
        "    Basically works like a linear layer but the weights are transposed.\n",
        "\n",
        "    Args:\n",
        "        nf (:obj:`int`): The number of output features.\n",
        "        nx (:obj:`int`): The number of input features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nf, nx):\n",
        "        super().__init__()\n",
        "        self.nf = nf\n",
        "        w = torch.empty(nx, nf)\n",
        "        nn.init.normal_(w, std=0.02)\n",
        "        self.weight = nn.Parameter(w)\n",
        "        self.bias = nn.Parameter(torch.zeros(nf))\n",
        "\n",
        "    def forward(self, x):\n",
        "        breakpoint()\n",
        "        size_out = x.size()[:-1] + (self.nf,)\n",
        "        x = torch.addmm(self.bias, x.view(-1, x.size(-1)), self.weight)\n",
        "        x = x.view(*size_out)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(dim_in, dim_out * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, gate = self.proj(x).chunk(2, dim=-1)\n",
        "        return x * F.gelu(gate)\n",
        "\n",
        "\n",
        "class GEGLUNarow(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(dim_in, dim_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, gate = self.proj(x).chunk(2, dim=-1)\n",
        "        return x * F.gelu(gate)\n",
        "\n",
        "\n",
        "class ScaleNorm(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.scale = dim ** -0.5\n",
        "        self.eps = eps\n",
        "        self.g = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = torch.norm(x, dim=-1, keepdim=True) * self.scale\n",
        "        return x / norm.clamp(min=self.eps) * self.g\n",
        "\n",
        "\n",
        "def init_(tensor):\n",
        "    dim = tensor.shape[-1]\n",
        "    std = 1 / math.sqrt(dim)\n",
        "    tensor.uniform_(-std, std)\n",
        "    return tensor\n",
        "\n",
        "\n",
        "class Rezero(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.g = nn.Parameter(torch.tensor(0.0))\n",
        "\n",
        "    def forward(self, fn, x):\n",
        "        return fn(x) * self.g\n",
        "\n",
        "\n",
        "## helpers\n",
        "def exists(val):\n",
        "    return val is not None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzsyTsKihYZA"
      },
      "source": [
        "**Embeddings**\n",
        "  * This code block provides functionality for embedding sequences of medical visits from the MIMIC dataset. It employs embeddings for various medical codes such as diagnoses, procedures, and medications, along with additional categorical features like service type, admission type, insurance, and marital status. The embeddings are augmented with axial positional encodings to capture sequential information effectively within each visit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z_WJpY5R5zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa290c60-1c64-4990-f32e-03c4f4b41422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_eEMGzZPmE7"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from functools import reduce\n",
        "\n",
        "import einops\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MIMICVisitwiseAxialEmbedding(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cfg = cfg\n",
        "\n",
        "        embed_size = self.cfg.MODEL.EMBED_SIZE\n",
        "        vocab_size = self.cfg.MODEL.VOCAB_SIZE\n",
        "\n",
        "        self.token_embed = nn.Embedding(vocab_size, embed_size - 8)\n",
        "        self.embed_sum = EmbeddingAdder()\n",
        "\n",
        "        self.delta_temb = DeltTEncoding(embed_size - 8, dropout=0.1, max_len=100000)\n",
        "        self.pos_embedding = FixedAxialPositionalEncoding(embed_size - 8, dropout=0.1)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        diag_seq,\n",
        "        proc_seq,\n",
        "        drug_seq,\n",
        "        delta_t,\n",
        "        service,\n",
        "        admtype,\n",
        "        insur,\n",
        "        marit,\n",
        "        seq_length,\n",
        "    ):\n",
        "        # taking intervals of every 15 days instead of everyday\n",
        "        # could improve perf\n",
        "        delta_t.div_(15.0)\n",
        "\n",
        "        indices = torch.arange(seq_length.max(), device=diag_seq.device)\n",
        "        len_mask = indices.view(1, -1) < seq_length.view(-1, 1)\n",
        "\n",
        "        # delta_t.clamp_(0, 999)\n",
        "        delta_t = delta_t.round().cumsum(dim=1)\n",
        "        delta_t = delta_t * len_mask.int()\n",
        "        doy_embedded = self.delta_temb(delta_t.long())[:, :, None, :]\n",
        "\n",
        "        icd_embed_sum = self.token_embed(diag_seq)\n",
        "        proc_embed_sum = self.token_embed(proc_seq)\n",
        "        drug_embed_sum = self.token_embed(drug_seq)\n",
        "        service_embed = self.token_embed(service)\n",
        "        admtype_embed = self.token_embed(admtype)\n",
        "\n",
        "        # position embedding\n",
        "        b, t, v, e = icd_embed_sum.size()\n",
        "\n",
        "        insur_embed = self.token_embed(insur)[:, :, None, :]\n",
        "        marit_embed = self.token_embed(marit)[:, :, None, :]\n",
        "\n",
        "        visit_embed = torch.cat(\n",
        "            [\n",
        "                icd_embed_sum,\n",
        "                proc_embed_sum,\n",
        "                drug_embed_sum,\n",
        "                service_embed,\n",
        "                admtype_embed,\n",
        "                insur_embed,\n",
        "                marit_embed,\n",
        "                doy_embedded,\n",
        "            ],\n",
        "            dim=2,\n",
        "        )\n",
        "        visit_embed = self.pos_embedding(visit_embed)\n",
        "\n",
        "        b, t, v, e = visit_embed.shape\n",
        "\n",
        "        return F.layer_norm(visit_embed, [t, v, e])\n",
        "\n",
        "\n",
        "## Transformer Helper Embeddings\n",
        "class AbsolutePositionalEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_seq_len):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(max_seq_len, dim)\n",
        "        self.init_()\n",
        "\n",
        "    def init_(self):\n",
        "        nn.init.normal_(self.emb.weight, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n = torch.arange(x.shape[1], device=x.device)\n",
        "        return self.emb(n)[None, :, :]\n",
        "\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    \"Implement the PE function.\"\n",
        "\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe[None, :, :]\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, : x.size(1)].detach()\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class FixedAxialPositionalEncoding(FixedPositionalEncoding):\n",
        "    \"Implement the PE function.\"\n",
        "\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__(d_model, dropout, max_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, t, v, e = x.shape\n",
        "        penc = self.pe[:, : x.size(1)].detach()\n",
        "        x = x + einops.repeat(penc, \"b t e -> b t v e\", v=v)\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class DeltTEncoding(nn.Module):\n",
        "    \"Implement the PE function specifically for delta_t.\"\n",
        "\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, delta_t):\n",
        "        # delta_t will be a cummulative number so we will just pick\n",
        "        # the corresponding indices from the positional encoding tensor\n",
        "        b, t = delta_t.shape\n",
        "        e = self.pe.shape[-1]\n",
        "        res_enc = torch.zeros((b, t, e)).to(delta_t.device)\n",
        "        # TODO fix this embarrasing for-loop\n",
        "        for i in range(b):\n",
        "            res_enc[i, :, :] = self.pe[:, delta_t[i], :]\n",
        "\n",
        "        return res_enc\n",
        "\n",
        "\n",
        "class EmbeddingAdder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x, dim=2):\n",
        "        return x.sum(dim=dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcfgxeOvTW4I"
      },
      "source": [
        "**Configuration**\n",
        "  * This configuration includes options for configuring various aspects of the model, training, testing, data loading, memory usage, and more. We can customize parameters such as model type, embedding size, vocabulary size, optimizer settings, batch normalization options, and data loader configurations. Additionally, it supports options for training on multiple GPUs, enabling automatic mixed precision, logging to TensorBoard, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNjZ6_0WUZ61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f7f220-fa6f-4fa4-a954-d4601566ac4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yacs in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install yacs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oZF-IanTWIS"
      },
      "outputs": [],
      "source": [
        "\"\"\"Configuration file (powered by YACS).\"\"\"\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from yacs.config import CfgNode as CN\n",
        "\n",
        "# Global config object\n",
        "_C = CN()\n",
        "\n",
        "# Example usage:\n",
        "#   from core.config import cfg\n",
        "cfg = _C\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Model options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.MODEL = CN()\n",
        "\n",
        "# Model type\n",
        "_C.MODEL.TYPE = \"\"\n",
        "\n",
        "# Topcap for the count regression prediction\n",
        "_C.MODEL.TOP_CAP = 24\n",
        "\n",
        "_C.MODEL.EMBED_SIZE = 128\n",
        "\n",
        "_C.MODEL.DROPOUT_P = 0.0\n",
        "\n",
        "_C.MODEL.VOCAB_SIZE = 1000\n",
        "_C.MODEL.DIAG_INPUT_VOCAB_SIZE = 1000\n",
        "_C.MODEL.PROC_INPUT_VOCAB_SIZE = 1000\n",
        "_C.MODEL.ICPC_INPUT_VOCAB_SIZE = 1000\n",
        "\n",
        "_C.MODEL.SPECIALITY_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.SERVICE_PROVIDER_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.SERVICE_SECTOR_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.NOTIFICATION_TYPE_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.REGISTER_TYPE_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.PALVELUMUOTO_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.YHTEYSTAPA_INPUT_VOCAB_SIZE = 10\n",
        "_C.MODEL.PROFESSIONAL_INPUT_VOCAB_SIZE = 10\n",
        "\n",
        "_C.MODEL.VOCAB_SIZE = 258\n",
        "_C.MODEL.MAX_SEQ_LENGTH = 200\n",
        "\n",
        "# RNN params\n",
        "_C.MODEL.RNN_HIDDEN_SIZE = 64\n",
        "_C.MODEL.RNN_DEPTH = 2\n",
        "\n",
        "# Transformer Params\n",
        "_C.MODEL.NUM_HEADS = 6\n",
        "_C.MODEL.TRANS_DEPTH = 2\n",
        "\n",
        "# Accumulate Gradient Steps\n",
        "_C.MODEL.ACCU_GRAD_STEPS = 3\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Batch norm options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.BN = CN()\n",
        "\n",
        "# BN epsilon\n",
        "_C.BN.EPS = 1e-5\n",
        "\n",
        "# BN momentum (BN momentum in PyTorch = 1 - BN momentum in Caffe2)\n",
        "_C.BN.MOM = 0.1\n",
        "\n",
        "# Precise BN stats\n",
        "_C.BN.USE_PRECISE_STATS = False\n",
        "_C.BN.NUM_SAMPLES_PRECISE = 1024\n",
        "\n",
        "# Initialize the gamma of the final BN of each block to zero\n",
        "_C.BN.ZERO_INIT_FINAL_GAMMA = False\n",
        "\n",
        "# Use a different weight decay for BN layers\n",
        "_C.BN.USE_CUSTOM_WEIGHT_DECAY = False\n",
        "_C.BN.CUSTOM_WEIGHT_DECAY = 0.0\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Optimizer options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.OPTIM = CN()\n",
        "\n",
        "# Base learning rate\n",
        "_C.OPTIM.BASE_LR = 0.1\n",
        "\n",
        "# Learning rate policy select from {'cos', 'exp', 'steps', '1cycle'}\n",
        "_C.OPTIM.LR_POLICY = \"cos\"\n",
        "\n",
        "# number of iters for lr warmup\n",
        "_C.OPTIM.LR_WARMUP = 0\n",
        "\n",
        "# factor for noam optimizer\n",
        "_C.OPTIM.NOAM_FACTOR = 2.0\n",
        "\n",
        "# Exponential decay factor\n",
        "_C.OPTIM.LR_GAMMA = 0.1\n",
        "\n",
        "# Steps for 'steps' policy (in epochs)\n",
        "_C.OPTIM.STEPS = []\n",
        "\n",
        "# Number of steps per epoch\n",
        "_C.OPTIM.STEPS_PER_EPOCH = 1\n",
        "\n",
        "# Learning rate multiplier for 'steps' policy\n",
        "_C.OPTIM.LR_MULT = 0.1\n",
        "\n",
        "# Maximal number of epochs\n",
        "_C.OPTIM.MAX_EPOCHS = 2\n",
        "\n",
        "# Momentum\n",
        "_C.OPTIM.MOMENTUM = 0.9\n",
        "\n",
        "# Momentum dampening\n",
        "_C.OPTIM.DAMPENING = 0.0\n",
        "\n",
        "# Nesterov momentum\n",
        "_C.OPTIM.NESTEROV = True\n",
        "\n",
        "# L2 regularization\n",
        "_C.OPTIM.WEIGHT_DECAY = 5e-4\n",
        "\n",
        "# Start the warm up from OPTIM.BASE_LR * OPTIM.WARMUP_FACTOR\n",
        "_C.OPTIM.WARMUP_FACTOR = 0.1\n",
        "\n",
        "# Gradually warm up the OPTIM.BASE_LR over this number of epochs\n",
        "_C.OPTIM.WARMUP_EPOCHS = 0\n",
        "\n",
        "# Grad clipping value for exploding gradients\n",
        "_C.OPTIM.GRAD_CLIP_T = 0.5\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Training options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.TRAIN = CN()\n",
        "\n",
        "# Dataset filename\n",
        "_C.TRAIN.FILENAME = \"\"\n",
        "\n",
        "# Dataset and split\n",
        "_C.TRAIN.DATASET = \"\"\n",
        "\n",
        "\n",
        "# column names of icd and proc in the dataframe\n",
        "_C.TRAIN.ICD_COLNAME = \"\"\n",
        "_C.TRAIN.PROC_COLNAME = \"\"\n",
        "\n",
        "# Size of validation set\n",
        "_C.TRAIN.VALIDATION_SPLIT = 0.01\n",
        "\n",
        "# Total mini-batch size\n",
        "_C.TRAIN.BATCH_SIZE = 2\n",
        "\n",
        "# Evaluate model on test data every eval period epochs\n",
        "_C.TRAIN.EVAL_PERIOD = 1\n",
        "\n",
        "# Save model checkpoint every checkpoint period epochs\n",
        "_C.TRAIN.CHECKPOINT_PERIOD = 1\n",
        "\n",
        "# Resume training from the latest checkpoint in the output directory\n",
        "_C.TRAIN.AUTO_RESUME = True\n",
        "\n",
        "# Weights to start training from\n",
        "_C.TRAIN.WEIGHTS = \"\"\n",
        "\n",
        "# Patience for early stopping\n",
        "_C.TRAIN.ES_PATIENCE = 0\n",
        "\n",
        "# Loss threshold for early stopping\n",
        "_C.TRAIN.ES_THRESHOLD = 0.0\n",
        "\n",
        "# After training, load the model with best val loss for evaluation?\n",
        "_C.TRAIN.LOAD_BEST_CKPT = True\n",
        "\n",
        "# Boolean flag for if test run is needed\n",
        "_C.TRAIN.IS_TEST_RUN_NEEDED = True\n",
        "\n",
        "# Boolean flag for if binary prediction is needed\n",
        "_C.TRAIN.IS_BINARY_PRED_NEEDED = True\n",
        "\n",
        "# Boolean flag for if seq regression prediction is needed\n",
        "_C.TRAIN.IS_DIST_PRED_NEEDED = False\n",
        "\n",
        "# Set this flag to true when we are finetuning the GPT model\n",
        "_C.TRAIN.IS_SUPERVISED = False\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Testing options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.TEST = CN()\n",
        "\n",
        "# Dataset filename\n",
        "_C.TEST.FILENAME = \"\"\n",
        "\n",
        "_C.TEST.FILENAME2 = \"\"\n",
        "\n",
        "# Dataset filename\n",
        "_C.TEST.VAL_FILENAME = \"\"\n",
        "\n",
        "# Dataset and split\n",
        "_C.TEST.DATASET = _C.TRAIN.DATASET\n",
        "\n",
        "# Total mini-batch size\n",
        "_C.TEST.BATCH_SIZE = 2\n",
        "\n",
        "# Weights to use for testing\n",
        "_C.TEST.WEIGHTS = \"\"\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Common train/test data loader options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.DATALOADER = CN()\n",
        "\n",
        "# Number of data loader workers per training process\n",
        "_C.DATALOADER.NUM_WORKERS = 0\n",
        "\n",
        "# Load data to pinned host memory\n",
        "_C.DATALOADER.PIN_MEMORY = True\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Memory options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.MEM = CN()\n",
        "\n",
        "# Perform ReLU inplace\n",
        "_C.MEM.RELU_INPLACE = True\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# CUDNN options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.CUDNN = CN()\n",
        "\n",
        "# Perform benchmarking to select the fastest CUDNN algorithms to use\n",
        "# Note that this may increase the memory usage and will likely not result\n",
        "# in overall speedups when variable size inputs are used (e.g. COCO training)\n",
        "_C.CUDNN.BENCHMARK = True\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Precise timing options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.PREC_TIME = CN()\n",
        "\n",
        "# Perform precise timing at the start of training\n",
        "_C.PREC_TIME.ENABLED = False\n",
        "\n",
        "# Total mini-batch size\n",
        "_C.PREC_TIME.BATCH_SIZE = 128\n",
        "\n",
        "# Number of iterations to warm up the caches\n",
        "_C.PREC_TIME.WARMUP_ITER = 3\n",
        "\n",
        "# Number of iterations to compute avg time\n",
        "_C.PREC_TIME.NUM_ITER = 30\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Path options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "_C.PATHS = CN()\n",
        "# Data Path\n",
        "_C.PATHS.DATAPATH = \"\"\n",
        "# Data file\n",
        "_C.PATHS.DATAFILE = \"\"\n",
        "# Output directory parent folder\n",
        "_C.PATHS.OUT_DIR = \"\"\n",
        "# Results log file name\n",
        "_C.PATHS.RESULTS_LOG_FILENAME = \"results.csv\"\n",
        "# Experiment name\n",
        "_C.PATHS.EXPERIMENT_NAME = \"\"\n",
        "# Experiment description\n",
        "_C.PATHS.EXPERIMENT_DESC = \"\"\n",
        "# Get current timestamp\n",
        "_C.PATHS.TIMESTAMP = \"at_\" + datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "# Outdirectory for TB logging\n",
        "_C.PATHS.TB_OUT_DIR = \"\"\n",
        "# Outdirectory for model checkpoints\n",
        "_C.PATHS.MODEL_OUT_DIR = \"\"\n",
        "# path to pretrained transformer file (if any)\n",
        "_C.PATHS.PRETRAINED_TRANSFORMER_FILE = \"\"\n",
        "# path to vectorizer (optional)\n",
        "_C.PATHS.VECTORIZER_PATH = \"./drive/MyDrive/mimic-iv-1.0/vectorizer.pickle\"\n",
        "\n",
        "# ---------------------------------------------------------------------------- #\n",
        "# Misc options\n",
        "# ---------------------------------------------------------------------------- #\n",
        "\n",
        "# try fitting the model on a small dataset ~ 20 examples\n",
        "_C.OVERFIT_ON_BATCH = False\n",
        "# overfit on batch percentage\n",
        "_C.OVERFIT_ON_BATCH_PCT = 1.0\n",
        "\n",
        "# Build vecotorizer from scratch\n",
        "_C.BUILD_VEC_FROM_SCRATCH = False\n",
        "\n",
        "# tune params if set to true, tunes model between a range of param values by using run_optuna method\n",
        "_C.TUNE_PARAMS = False\n",
        "\n",
        "# Number of trials while tuning params\n",
        "_C.NUM_TRIALS = 1\n",
        "\n",
        "# Choose device type\n",
        "_C.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Number of GPUs to use (applies to both training and testing)\n",
        "_C.GPU_NUM = 1\n",
        "\n",
        "# Config destination (in OUT_DIR)\n",
        "_C.CFG_DEST = \"config.yaml\"\n",
        "\n",
        "# create a git tag based on experiment name and description\n",
        "_C.CREATE_GIT_TAG = False\n",
        "\n",
        "# Note that non-determinism may still be present due to non-deterministic\n",
        "# operator implementations in GPU operator libraries\n",
        "_C.RNG_SEED = 100\n",
        "\n",
        "# Log destination ('stdout' or 'file')\n",
        "_C.LOG_DEST = \"stdout\"\n",
        "\n",
        "# Log period in iters\n",
        "_C.LOG_PERIOD = 10\n",
        "\n",
        "# Tensorboard logging flag\n",
        "_C.IS_TB_LOG = True\n",
        "\n",
        "# Verbose flag for print logs\n",
        "_C.VERBOSE = True\n",
        "\n",
        "# Frequency for logging gradient histograms in TB\n",
        "_C.TB_LOG_GRAD_INTV = 500  # iteration\n",
        "\n",
        "# use AMP\n",
        "_C.USE_AMP = False\n",
        "\n",
        "# Multiple GPUS\n",
        "_C.MULTI_GPU = False\n",
        "\n",
        "\n",
        "def assert_and_infer_cfg(cache_urls=True):\n",
        "    \"\"\"Checks config values invariants.\"\"\"\n",
        "    pass\n",
        "\n",
        "\n",
        "def dump_cfg(cfg):\n",
        "    \"\"\"Dumps the config to the output directory.\"\"\"\n",
        "    cfg_file = os.path.join(cfg.PATHS.OUT_DIR, cfg.CFG_DEST)\n",
        "    with open(cfg_file, \"w\") as f:\n",
        "        cfg.dump(stream=f)\n",
        "\n",
        "\n",
        "def load_cfg(out_dir, cfg_dest=\"config.yaml\"):\n",
        "    \"\"\"Loads config from specified output directory.\"\"\"\n",
        "    cfg_file = os.path.join(out_dir, cfg_dest)\n",
        "    _C.merge_from_file(cfg_file)\n",
        "\n",
        "\n",
        "def get_cfg_defaults():\n",
        "    \"\"\"Get a yacs CfgNode object with default values for my_project.\"\"\"\n",
        "    # Return a clone so that the defaults will not be altered\n",
        "    # This is for the \"local variable\" use pattern\n",
        "    return _C.clone()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0eKjeSmTcC2"
      },
      "source": [
        "**Loss Functions**\n",
        "  1. **softmax_focal_loss:** Computes the softmax focal loss, which is a modification of the cross-entropy loss that focuses on hard-to-classify examples by down-weighting easy examples and emphasizing hard ones.\n",
        "\n",
        "  2. **zero_inflated_poisson_loss:** Computes the zero-inflated Poisson loss, suitable for count data with an excess of zeros, by combining binary cross-entropy and Poisson loss components based on a learned inflation probability.\n",
        "\n",
        "  3. **gaussian_nll_loss:** Computes the negative log-likelihood loss for Gaussian distributions, which is suitable for regression tasks where the target values are assumed to follow Gaussian distributions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yWoW_meTbeD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "Tensor = torch.Tensor\n",
        "\n",
        "\n",
        "def softmax_focal_loss(x, target, gamma=2.0, alpha=0.25):\n",
        "    n = x.shape[0]\n",
        "    device = target.device\n",
        "    range_n = torch.arange(0, n, dtype=torch.int64, device=device)\n",
        "\n",
        "    pos_num = float(x.shape[1])\n",
        "    p = torch.softmax(x, dim=1)\n",
        "    p = p[range_n, target]\n",
        "    loss = -((1 - p) ** gamma) * alpha * torch.log(p)\n",
        "    return torch.sum(loss) / pos_num\n",
        "\n",
        "\n",
        "def zero_inflated_poisson_loss(input, target, p_logit, log_input=True, full=True):\n",
        "\n",
        "    count_ones = torch.ones_like(target).to(target.device)\n",
        "    count_zeros = torch.zeros_like(target).to(target.device)\n",
        "    # set bce target to true if original count is 0 and false otherwise\n",
        "    count_true_zeros = torch.where(target == 0, count_ones, count_zeros)\n",
        "    p_value = torch.sigmoid(p_logit)\n",
        "\n",
        "    loss_y0 = torch.log((1 - p_value) * torch.exp(-1 * input) + p_value)\n",
        "\n",
        "    bce_loss_vec = torch.nn.functional.binary_cross_entropy_with_logits(\n",
        "        p_logit, count_true_zeros.float(), reduction=\"none\"\n",
        "    )\n",
        "    unweighted_poisson_loss_vec = torch.nn.functional.poisson_nll_loss(\n",
        "        input, target.float(), reduction=\"none\", log_input=log_input, full=full\n",
        "    )\n",
        "    weighted_poisson_loss_vec = (1 - p_value) * unweighted_poisson_loss_vec\n",
        "\n",
        "    loss_y1 = bce_loss_vec + weighted_poisson_loss_vec\n",
        "\n",
        "    loss = torch.where(target == 0, loss_y0, loss_y1)\n",
        "\n",
        "    return loss.mean(), unweighted_poisson_loss_vec.mean()\n",
        "\n",
        "\n",
        "# https://pytorch.org/docs/stable/_modules/torch/nn/functional.html#gaussian_nll_loss\n",
        "def gaussian_nll_loss(input, target, var, *, full=False, eps=1e-6, reduction=\"mean\"):\n",
        "    r\"\"\"Gaussian negative log likelihood loss.\n",
        "\n",
        "    See :class:`~torch.nn.GaussianNLLLoss` for details.\n",
        "\n",
        "    Args:\n",
        "        input: expectation of the Gaussian distribution.\n",
        "        target: sample from the Gaussian distribution.\n",
        "        var: tensor of positive variance(s), one for each of the expectations\n",
        "            in the input (heteroscedastic), or a single one (homoscedastic).\n",
        "        full: ``True``/``False`` (bool), include the constant term in the loss\n",
        "            calculation. Default: ``False``.\n",
        "        eps: value added to var, for stability. Default: 1e-6.\n",
        "        reduction: specifies the reduction to apply to the output:\n",
        "            `'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
        "            ``'mean'``: the output is the average of all batch member losses,\n",
        "            ``'sum'``: the output is the sum of all batch member losses.\n",
        "            Default: ``'mean'``.\n",
        "    \"\"\"\n",
        "    # Inputs and targets much have same shape\n",
        "    input = input.view(input.size(0), -1)\n",
        "    target = target.view(target.size(0), -1)\n",
        "    if input.size() != target.size():\n",
        "        raise ValueError(\"input and target must have same size\")\n",
        "\n",
        "    # Second dim of var must match that of input or be equal to 1\n",
        "    var = var.view(input.size(0), -1)\n",
        "    if var.size(1) != input.size(1) and var.size(1) != 1:\n",
        "        raise ValueError(\"var is of incorrect size\")\n",
        "\n",
        "    # Check validity of reduction mode\n",
        "    if reduction != \"none\" and reduction != \"mean\" and reduction != \"sum\":\n",
        "        raise ValueError(reduction + \" is not valid\")\n",
        "\n",
        "    # Entries of var must be non-negative\n",
        "    if torch.any(var < 0):\n",
        "        raise ValueError(\"var has negative entry/entries\")\n",
        "\n",
        "    # Clamp for stability\n",
        "    var = var.clone()\n",
        "    with torch.no_grad():\n",
        "        var.clamp_(min=eps)\n",
        "\n",
        "    # Calculate loss (without constant)\n",
        "    loss = 0.5 * (torch.log(var) + (input - target) ** 2 / var).view(\n",
        "        input.size(0), -1\n",
        "    ).sum(dim=1)\n",
        "\n",
        "    # Add constant to loss term if required\n",
        "    if full:\n",
        "        D = input.size(1)\n",
        "        loss = loss + 0.5 * D * math.log(2 * math.pi)\n",
        "\n",
        "    # Apply reduction\n",
        "    if reduction == \"mean\":\n",
        "        return loss.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        return loss.sum()\n",
        "    else:\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6_8so1wSkMK"
      },
      "source": [
        "**Utils**\n",
        "  1. **Commons:** Contains various utility functions and helper methods used for tasks such as argument parsing, setting random seeds, handling configurations and logging paths, plotting gradients, cloning modules, and counting parameters in a model.\n",
        "\n",
        "  2. **Learning Rate Policies:** Defines functions related to handling configurations, logging test results to a CSV file, and counting parameters in a model. It also includes a function for seeding random number generators, computing the number of NaN values in a DataFrame, and implementing a thresholded sigmoid function for binary classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9DnnsfRmvLq"
      },
      "source": [
        "**Commons**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcwd8u4BSyeJ"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import collections\n",
        "import copy\n",
        "import csv\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib.pyplot import Line2D\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# from core.config import assert_and_infer_cfg, dump_cfg, get_cfg_defaults\n",
        "\n",
        "def parse_args():\n",
        "    \"\"\"Parses the arguments.\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"parser\")\n",
        "    parser.add_argument(\n",
        "        \"--cfg\", dest=\"cfg_file\", help=\"Config file\", required=True, type=str\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"opts\",\n",
        "        help=\"See src/config.py for all options\",\n",
        "        default=None,\n",
        "        nargs=argparse.REMAINDER,\n",
        "    )\n",
        "    if len(sys.argv) == 1:\n",
        "        parser.print_help()\n",
        "        sys.exit(1)\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def how_many_nas(df):\n",
        "    ctr = collections.Counter()\n",
        "    for col in df.columns:\n",
        "        ctr.update({col: df[col].isnull().sum()})\n",
        "    print(f\"Total columns: {df.shape[0]}\")\n",
        "    for el in ctr.most_common():\n",
        "        print(el)\n",
        "\n",
        "\n",
        "def threshed_sigmoid(logits, threshold=0.5):\n",
        "    return torch.where(\n",
        "        torch.sigmoid(logits) > threshold,\n",
        "        torch.ones_like(logits),\n",
        "        torch.zeros_like(logits),\n",
        "    )\n",
        "\n",
        "\n",
        "def fetch_best_model_filename(model_save_path):\n",
        "    checkpoint_files = os.listdir(model_save_path)\n",
        "    best_checkpoint_files = [f for f in checkpoint_files if \"best_\" in f]\n",
        "    best_checkpoint_val_loss = [\n",
        "        float(\".\".join(x.split(\"=\")[1].split(\".\")[0:2])) for x in best_checkpoint_files\n",
        "    ]\n",
        "    best_idx = np.array(best_checkpoint_val_loss).argmax()\n",
        "    return os.path.join(model_save_path, best_checkpoint_files[best_idx])\n",
        "\n",
        "\n",
        "def plot_grad_flow(named_parameters):\n",
        "    \"\"\"Plots the gradients flowing through different layers in the net during training.\n",
        "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "\n",
        "    Usage: Plug this function in Trainer class after loss.backwards() as\n",
        "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow\"\"\"\n",
        "    # ref: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/10\n",
        "    ave_grads = []\n",
        "    max_grads = []\n",
        "    layers = []\n",
        "    for n, p in named_parameters:\n",
        "        if (p.requires_grad) and (\"bias\" not in n):\n",
        "            layers.append(n)\n",
        "            ave_grads.append(p.grad.abs().mean())\n",
        "            max_grads.append(p.grad.abs().max())\n",
        "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "    plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color=\"k\")\n",
        "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "    plt.xlim(left=0, right=len(ave_grads))\n",
        "    plt.ylim(bottom=-0.001, top=0.02)  # zoom in on the lower gradient regions\n",
        "    plt.xlabel(\"Layers\")\n",
        "    plt.ylabel(\"average gradient\")\n",
        "    plt.title(\"Gradient flow\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(\n",
        "        [\n",
        "            Line2D([0], [0], color=\"c\", lw=4),\n",
        "            Line2D([0], [0], color=\"b\", lw=4),\n",
        "            Line2D([0], [0], color=\"k\", lw=4),\n",
        "        ],\n",
        "        [\"max-gradient\", \"mean-gradient\", \"zero-gradient\"],\n",
        "    )\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return torch.nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "\n",
        "def handle_config_and_log_paths(args):\n",
        "    # Load default config options\n",
        "    cfg = get_cfg_defaults()\n",
        "    # merge config modifications from config file\n",
        "    cfg.merge_from_file(args.cfg_file)\n",
        "    # merge config modifications from command line arguments\n",
        "    cfg.merge_from_list(args.opts)\n",
        "    # checks and assertions on config\n",
        "    assert_and_infer_cfg()\n",
        "    cfg.PATHS.OUT_DIR = os.path.join(\n",
        "        cfg.PATHS.OUT_DIR, cfg.PATHS.EXPERIMENT_NAME, cfg.PATHS.TIMESTAMP\n",
        "    )\n",
        "    model_save_path = os.path.join(cfg.PATHS.DATAPATH, \"experiments/\")\n",
        "    cfg.PATHS.MODEL_OUT_DIR = os.path.join(\n",
        "        model_save_path, cfg.PATHS.EXPERIMENT_NAME, cfg.PATHS.TIMESTAMP, \"saved_models\"\n",
        "    )\n",
        "    cfg.PATHS.TB_OUT_DIR = os.path.join(cfg.PATHS.OUT_DIR, \"tb_logs\")\n",
        "\n",
        "    # freeze config before running experiments\n",
        "    cfg.freeze()\n",
        "\n",
        "    # Ensure that the output dir exists\n",
        "    try:\n",
        "        os.makedirs(cfg.PATHS.OUT_DIR, exist_ok=True)\n",
        "        os.makedirs(cfg.PATHS.MODEL_OUT_DIR, exist_ok=True)\n",
        "        os.makedirs(cfg.PATHS.TB_OUT_DIR, exist_ok=False)\n",
        "    except FileExistsError:\n",
        "        print(\"Wait for a minute and try again :)\")\n",
        "        exit()\n",
        "\n",
        "    dump_cfg(cfg)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def log_test_results_to_csv(cfg, file_path, test_metrics_l):\n",
        "    for i, test_metrics_d in enumerate(test_metrics_l):\n",
        "        test_metrics_d.update(\n",
        "            {\n",
        "                \"base_lr\": cfg.OPTIM.BASE_LR,\n",
        "                \"lr_policy\": cfg.OPTIM.LR_POLICY,\n",
        "                \"batch_size\": cfg.TRAIN.BATCH_SIZE,\n",
        "                \"optim_momentum\": cfg.OPTIM.MOMENTUM,\n",
        "                \"max_seq_length\": cfg.MODEL.MAX_SEQ_LENGTH,\n",
        "                \"embed_size\": cfg.MODEL.EMBED_SIZE,\n",
        "                \"max_epochs\": cfg.OPTIM.MAX_EPOCHS,\n",
        "                \"exp_dir\": cfg.PATHS.OUT_DIR,\n",
        "                \"exp_name\": cfg.PATHS.EXPERIMENT_NAME,\n",
        "                \"test_id\": i,\n",
        "            }\n",
        "        )\n",
        "        log_file = Path(file_path)\n",
        "        if not log_file.is_file():\n",
        "            with open(file_path, \"w\", newline=\"\") as csvfile:\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=test_metrics_d.keys())\n",
        "                writer.writeheader()\n",
        "                writer.writerow(test_metrics_d)\n",
        "        else:\n",
        "            with open(file_path, \"a\", newline=\"\") as csvfile:\n",
        "                writer = csv.DictWriter(csvfile, fieldnames=test_metrics_d.keys())\n",
        "                writer.writerow(test_metrics_d)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params += param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43SN6hZpmyaC"
      },
      "source": [
        "**Learning Rate Policies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NySG8xWiSmpT"
      },
      "outputs": [],
      "source": [
        "\"\"\"Learning rate policies.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def lr_sched_steps(cfg, optimizer):\n",
        "    \"\"\"Steps schedule (cfg.OPTIM.LR_POLICY = 'steps').\"\"\"\n",
        "    return torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer, lambda i: min(i / (cfg.OPTIM.LR_WARMUP / cfg.TRAIN.BATCH_SIZE), 1.0)\n",
        "    )\n",
        "\n",
        "\n",
        "def lr_sched_const(cfg, optimizer):\n",
        "    \"\"\"Steps schedule (cfg.OPTIM.LR_POLICY = 'const').\"\"\"\n",
        "    return torch.optim.lr_scheduler.MultiplicativeLR(\n",
        "        optimizer, lambda ep: 1.0, last_epoch=-1\n",
        "    )\n",
        "\n",
        "\n",
        "def lr_sched_exp(cfg, optimizer):\n",
        "    \"\"\"Exponential schedule (cfg.OPTIM.LR_POLICY = 'exp').\"\"\"\n",
        "    return torch.optim.lr_scheduler.ExponentialLR(\n",
        "        optimizer, cfg.OPTIM.LR_GAMMA, last_epoch=-1\n",
        "    )\n",
        "\n",
        "\n",
        "def lr_sched_cos(cfg, optimizer):\n",
        "    \"\"\"Cosine schedule (cfg.OPTIM.LR_POLICY = 'cos').\"\"\"\n",
        "    return torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=cfg.OPTIM.LR_WARMUP, T_mult=1, eta_min=1e-5, last_epoch=-1\n",
        "    )\n",
        "\n",
        "\n",
        "def lr_sched_1cycle(cfg, optimizer):\n",
        "    \"\"\"Cosine schedule (cfg.OPTIM.LR_POLICY = '1cycle').\"\"\"\n",
        "    return torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=cfg.OPTIM.BASE_LR,\n",
        "        anneal_strategy=\"linear\",\n",
        "        epochs=cfg.OPTIM.MAX_EPOCHS,\n",
        "        steps_per_epoch=cfg.OPTIM.STEPS_PER_EPOCH,\n",
        "    )\n",
        "\n",
        "\n",
        "def get_lr_sched(cfg, optimizer):\n",
        "    \"\"\"Retrieves the specified lr policy function\"\"\"\n",
        "    lr_fun = \"lr_sched_\" + cfg.OPTIM.LR_POLICY\n",
        "    if lr_fun not in globals():\n",
        "        raise NotImplementedError(\"Unknown LR policy:\" + cfg.OPTIM.LR_POLICY)\n",
        "    return globals()[lr_fun](cfg, optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD6N1-6ypcI4"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJThd0DnzEsT"
      },
      "source": [
        "**MIMIC Axial Sansformer Model:**\n",
        "  * **Layers:** The model consists of multiple layers of the Sansformer architecture, which includes both causal and non-causal Sansformer layers.\n",
        "  * **Embeddings:** The model utilizes axial embeddings for the MIMIC dataset, including visit-wise embeddings for diagnoses, procedures, and DRGs, along with additional embeddings for demographic features.\n",
        "  * **Activation Function:** The model uses GELU activation function.\n",
        "  * **Initialization:** The weights of linear and embedding layers are initialized using a normal distribution with mean 0 and standard deviation 0.02, and layer normalization parameters are initialized with zeros for bias and ones for weight.\n",
        "  * **Masking:** The model generates a causal mask for ensuring causality in the self-attention mechanism."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSHEBCeRwgXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b3761c-a8f1-4e1c-d517-0c5ba3468ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.2.1+cu121)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torch_optimizer) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "import warnings\n",
        "\n",
        "import einops\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_optimizer as t_optim\n",
        "\n",
        "# import utils.lr_policy as lr_policy\n",
        "# from models.attention_blocks import SansformerLayer\n",
        "# from models.embeddings import MIMICVisitwiseAxialEmbedding\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "\n",
        "class MimicAxialSansformerModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cfg = cfg\n",
        "\n",
        "        embed_size = self.cfg.MODEL.EMBED_SIZE\n",
        "        depth = self.cfg.MODEL.TRANS_DEPTH\n",
        "        self.dropout_p = self.cfg.MODEL.DROPOUT_P\n",
        "\n",
        "        self.pummel_embed = MIMICVisitwiseAxialEmbedding(cfg)\n",
        "        self.ethn_embed = nn.Embedding(8, 4)\n",
        "\n",
        "        self.sansformer = nn.ModuleList(\n",
        "            [\n",
        "                SansformerLayer(\n",
        "                    d_model=embed_size,\n",
        "                    causal=True,\n",
        "                    ff_hidden_mult=4,\n",
        "                    p_do=self.dropout_p,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.visit_sansformer = nn.ModuleList(\n",
        "            [\n",
        "                SansformerLayer(\n",
        "                    d_model=embed_size,\n",
        "                    causal=False,\n",
        "                    ff_hidden_mult=1,\n",
        "                    p_do=0.5,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.axial_alpha = 0.1\n",
        "\n",
        "        self.bin_fc = nn.Sequential(\n",
        "            nn.LayerNorm([embed_size]),\n",
        "            nn.Linear(embed_size, 1),\n",
        "        )\n",
        "\n",
        "        if cfg.PATHS.PRETRAINED_TRANSFORMER_FILE:\n",
        "            checkpoint = torch.load(\n",
        "                cfg.PATHS.PRETRAINED_TRANSFORMER_FILE, map_location=\"cpu\"\n",
        "            )\n",
        "            self.load_state_dict(checkpoint[\"model_state\"])\n",
        "            print(\"loaded pretrained model.\")\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        diag_seq,\n",
        "        proc_seq,\n",
        "        drg_seq,\n",
        "        seq_length,\n",
        "        delta_t,\n",
        "        age,\n",
        "        gender,\n",
        "        language,\n",
        "        ethnicity,\n",
        "        service,\n",
        "        admtype,\n",
        "        insurance,\n",
        "        marit,\n",
        "        y_outcome,\n",
        "        y_los,\n",
        "        y_next_v,\n",
        "        x_los,\n",
        "        x_next_v,\n",
        "        **kwargs\n",
        "    ):\n",
        "        batch_size, max_seq_length = delta_t.shape\n",
        "        seq_length = seq_length.long()\n",
        "        ethnicity_embed = self.ethn_embed(ethnicity.long())\n",
        "\n",
        "        x_num = torch.cat(\n",
        "            [\n",
        "                gender[:, None],\n",
        "                age[:, None],\n",
        "                language[:, None],\n",
        "                ethnicity_embed,\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        visit_embed = self.pummel_embed(\n",
        "            diag_seq,\n",
        "            proc_seq,\n",
        "            drg_seq,\n",
        "            delta_t,\n",
        "            service,\n",
        "            admtype,\n",
        "            insurance,\n",
        "            marit,\n",
        "            seq_length,\n",
        "        )\n",
        "\n",
        "        b, t, v, e = visit_embed.shape\n",
        "        x_num_ext = einops.repeat(x_num, \"b h -> b t h\", t=t)\n",
        "        x_ext = torch.cat([x_num_ext, x_los[:, :, None]], dim=-1)\n",
        "\n",
        "        # finally avg across intravisit_axis\n",
        "        add_embed = einops.reduce(visit_embed, \"b t v e -> b t e\", \"sum\")\n",
        "        x_trans = torch.cat([add_embed, x_num_ext, x_los[:, :, None]], dim=-1)\n",
        "\n",
        "        _, _, d_e = x_trans.shape\n",
        "        b, t, v, e = visit_embed.shape\n",
        "        for i, layer in enumerate(self.sansformer):\n",
        "            shortcut = x_trans  # b t d_e\n",
        "\n",
        "            x_visits = layer(F.layer_norm(x_trans, [t, d_e]))\n",
        "\n",
        "            bv, vt, vv, ve = visit_embed.shape\n",
        "            x_codes = visit_embed.reshape(bv * vt, vv, ve)\n",
        "            if i == 0:\n",
        "                x_codes = torch.cat(\n",
        "                    [x_codes, torch.zeros((bv * vt, vv, 8)).to(x_codes.device)], dim=-1\n",
        "                )\n",
        "\n",
        "            x_codes = self.visit_sansformer[i](\n",
        "                F.layer_norm(x_codes, x_codes.shape[-2:])\n",
        "            )\n",
        "            x_codes = x_codes.reshape(-1, t, v, d_e)\n",
        "            visit_embed = x_codes\n",
        "\n",
        "            x_codes = einops.reduce(x_codes, \"b t v e -> b t e\", \"mean\")\n",
        "            x_trans = self.axial_alpha * x_codes + x_visits\n",
        "\n",
        "            x_trans += shortcut\n",
        "\n",
        "        x_trans_max = einops.reduce(x_trans, \"b t e -> b e\", \"max\")\n",
        "        x_trans_avg = einops.reduce(x_trans, \"b t e -> b e\", \"mean\")\n",
        "        patient_vec = x_trans_avg + F.gelu(x_trans_max)\n",
        "\n",
        "        # bin\n",
        "        logit_pred = self.bin_fc(patient_vec)\n",
        "        y_pred_bin = torch.sigmoid(logit_pred)\n",
        "\n",
        "        bin_loss = F.binary_cross_entropy_with_logits(\n",
        "            logit_pred.view(-1),\n",
        "            y_outcome.float(),\n",
        "            reduction=\"mean\",\n",
        "            pos_weight=torch.tensor(3.0, device=y_pred_bin.device),\n",
        "        )\n",
        "\n",
        "        total_loss = bin_loss\n",
        "\n",
        "        return (\n",
        "            total_loss,\n",
        "            bin_loss,\n",
        "            bin_loss * 0,\n",
        "            y_pred_bin,\n",
        "            torch.zeros_like(y_pred_bin),\n",
        "            torch.zeros_like(y_pred_bin),\n",
        "            patient_vec,\n",
        "        )\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def generate_causal_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def configure_optimizers(self, cfg):\n",
        "        optimizer = t_optim.RAdam(\n",
        "            self.parameters(),\n",
        "            lr=cfg.OPTIM.BASE_LR,\n",
        "            weight_decay=cfg.OPTIM.WEIGHT_DECAY,\n",
        "            betas=(0.9, 0.99),\n",
        "            eps=1e-9,\n",
        "        )\n",
        "        scheduler = get_lr_sched(cfg, optimizer)\n",
        "\n",
        "        return optimizer, scheduler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FYBcV8RzL45"
      },
      "source": [
        "**MIMIC Additive Sansformer:**\n",
        "\n",
        "  * **Layers:** Similar to the Axial Sansformer model, this model also consists of multiple layers of the Sansformer architecture.\n",
        "  * **Embeddings:** Utilizes axial embeddings for the MIMIC dataset and additional embeddings for demographic features.\n",
        "  * **Activation Function:** Applies GELU activation function.\n",
        "  * **Initialization:** Weight initialization is the same as the Axial Sansformer model.\n",
        "  * **Masking:** Generates a causal mask similar to the Axial Sansformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPd_TjX7zQkZ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "import warnings\n",
        "\n",
        "import einops\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_optimizer as t_optim\n",
        "\n",
        "# import utils.lr_policy as lr_policy\n",
        "# from models.attention_blocks import SansformerLayer\n",
        "# from models.embeddings import MIMICVisitwiseAxialEmbedding\n",
        "\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "\n",
        "class MimicAdditiveSansformerModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cfg = cfg\n",
        "\n",
        "        embed_size = self.cfg.MODEL.EMBED_SIZE\n",
        "        depth = self.cfg.MODEL.TRANS_DEPTH\n",
        "        self.dropout_p = self.cfg.MODEL.DROPOUT_P\n",
        "\n",
        "        self.pummel_embed = MIMICVisitwiseAxialEmbedding(cfg)\n",
        "        self.ethn_embed = nn.Embedding(8, 4)\n",
        "\n",
        "        self.sansformer = nn.ModuleList(\n",
        "            [\n",
        "                SansformerLayer(\n",
        "                    d_model=embed_size,\n",
        "                    causal=True,\n",
        "                    ff_hidden_mult=4,\n",
        "                    p_do=self.dropout_p,\n",
        "                )\n",
        "                for _ in range(depth)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.bin_fc = nn.Sequential(\n",
        "            nn.LayerNorm([embed_size]),\n",
        "            nn.Linear(embed_size, 1),\n",
        "        )\n",
        "\n",
        "        if cfg.PATHS.PRETRAINED_TRANSFORMER_FILE:\n",
        "            checkpoint = torch.load(\n",
        "                cfg.PATHS.PRETRAINED_TRANSFORMER_FILE, map_location=\"cpu\"\n",
        "            )\n",
        "            self.load_state_dict(checkpoint[\"model_state\"])\n",
        "            print(\"loaded pretrained model.\")\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        diag_seq,\n",
        "        proc_seq,\n",
        "        drg_seq,\n",
        "        seq_length,\n",
        "        delta_t,\n",
        "        age,\n",
        "        gender,\n",
        "        language,\n",
        "        ethnicity,\n",
        "        service,\n",
        "        admtype,\n",
        "        insurance,\n",
        "        marit,\n",
        "        y_outcome,\n",
        "        y_los,\n",
        "        y_next_v,\n",
        "        x_los,\n",
        "        x_next_v,\n",
        "        **kwargs\n",
        "    ):\n",
        "        seq_lengths = seq_length.long()\n",
        "        ethnicity_embed = self.ethn_embed(ethnicity.long())\n",
        "\n",
        "        indices = torch.arange(seq_length.max(), device=seq_length.device)\n",
        "        len_mask = indices.view(1, -1) < seq_length.view(-1, 1)\n",
        "\n",
        "        x_num = torch.cat(\n",
        "            [\n",
        "                gender[:, None],\n",
        "                age[:, None],\n",
        "                language[:, None],\n",
        "                ethnicity_embed,\n",
        "            ],\n",
        "            dim=1,\n",
        "        )\n",
        "\n",
        "        visit_embed = self.pummel_embed(\n",
        "            diag_seq,\n",
        "            proc_seq,\n",
        "            drg_seq,\n",
        "            delta_t,\n",
        "            service,\n",
        "            admtype,\n",
        "            insurance,\n",
        "            marit,\n",
        "            seq_lengths,\n",
        "        )\n",
        "\n",
        "        add_embed = einops.reduce(visit_embed, \"b t v e -> b t e\", \"sum\")\n",
        "\n",
        "        b, t, e = add_embed.shape\n",
        "\n",
        "        x_num_ext = einops.repeat(x_num, \"b h -> b t h\", t=t)\n",
        "        x_trans = torch.cat([add_embed, x_num_ext, x_los[:, :, None]], dim=-1)\n",
        "\n",
        "        b, t, e = x_trans.shape\n",
        "        for layer in self.sansformer:\n",
        "            shortcut = x_trans  # b t e\n",
        "            x_trans = layer(F.layer_norm(x_trans, [t, e])) + shortcut\n",
        "\n",
        "        x_trans_max = einops.reduce(x_trans, \"b t e -> b e\", \"max\")\n",
        "        x_trans_avg = einops.reduce(x_trans, \"b t e -> b e\", \"mean\")\n",
        "        patient_vec = x_trans_avg + F.gelu(x_trans_max)\n",
        "\n",
        "        # bin\n",
        "        logit_pred = self.bin_fc(patient_vec)\n",
        "        # probs are needed for AUC score\n",
        "        y_pred_bin = torch.sigmoid(logit_pred)\n",
        "\n",
        "        bin_loss = F.binary_cross_entropy_with_logits(\n",
        "            logit_pred.view(-1),\n",
        "            y_outcome.float(),\n",
        "            reduction=\"mean\",\n",
        "            # add small positive weight to handle class imbalance\n",
        "            pos_weight=torch.tensor(3.0, device=y_pred_bin.device),\n",
        "        )\n",
        "\n",
        "        total_loss = bin_loss\n",
        "\n",
        "        #TODO returning some empty tensors for API conformity, needs cleanup\n",
        "        return (\n",
        "            total_loss,\n",
        "            bin_loss,\n",
        "            bin_loss * 0,\n",
        "            y_pred_bin,\n",
        "            torch.zeros_like(y_pred_bin),\n",
        "            torch.zeros_like(y_pred_bin),\n",
        "            patient_vec,\n",
        "        )\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "            module.weight.data.normal_(mean=0.0, std=0.02)\n",
        "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            module.bias.data.zero_()\n",
        "            module.weight.data.fill_(1.0)\n",
        "\n",
        "    def generate_causal_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def configure_optimizers(self, cfg):\n",
        "        optimizer = t_optim.RAdam(\n",
        "            self.parameters(),\n",
        "            lr=cfg.OPTIM.BASE_LR,\n",
        "            weight_decay=cfg.OPTIM.WEIGHT_DECAY,\n",
        "            betas=(0.9, 0.99),\n",
        "            eps=1e-9,\n",
        "        )\n",
        "        scheduler = get_lr_sched(cfg, optimizer)\n",
        "\n",
        "        return optimizer, scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdxHWmdszrbu"
      },
      "source": [
        "# Training\n",
        "\n",
        "* **Objectives:**\n",
        "  * **Loss Functions:** Please refer to the Loss Functions section for further details. Additionally, loss terms such as total loss, binary classification loss, and length of stay loss are computed during the training process and contribute to the optimization objective.\n",
        "  * **Optimizer:** The optimizer used is Rectified Adam as shown in the MIMIC Additive Sansformer and MIMIC Axial Sansformer sections. It is configured with a learning rate, cfg.OPTIM.BASE_LR, weight decay, cfg.OPTIM.WEIGHT_DECAY, betas value of (0.9, 0.99), and epsilon value set to 1e-9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EFB4D4azx-q"
      },
      "source": [
        "**Base Trainer**\n",
        "  * Provides a foundational framework for training neural network models, handling model initialization, automatic GPU configuration, metric recording, checkpointing, evaluation, and visualization functionalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZtqLSu4zs_i"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Base trainer class\n",
        "ref: https://github.com/karpathy/minGPT/blob/master/mingpt/trainer.py\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import Line2D\n",
        "from tqdm import tqdm\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "import scipy.stats as stats\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    cohen_kappa_score,\n",
        "    f1_score,\n",
        "    mean_absolute_error,\n",
        "    mean_poisson_deviance,\n",
        "    precision_score,\n",
        "    r2_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# from core.config import dump_cfg\n",
        "# from utils import common\n",
        "\n",
        "PLOT_STYLE = \"seaborn-muted\"\n",
        "\n",
        "\n",
        "class BaseTrainer:\n",
        "    def __init__(self, cfg, model, train_dataloader, val_dataloader, test_dataloaders):\n",
        "        self.model = model\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "        self.test_dataloaders = test_dataloaders\n",
        "        self.cfg = cfg\n",
        "        self.grad_scaler = GradScaler(enabled=cfg.USE_AMP)\n",
        "        self.best_epoch = 0\n",
        "\n",
        "        # take over whatever gpus are on the system\n",
        "        self.device = \"cpu\"\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda\", cfg.GPU_NUM)\n",
        "            self.model = self.model.to(self.device)\n",
        "\n",
        "        # names of the variables that we will keep track of\n",
        "        # during training and validation\n",
        "        self.track_metric_names = [\n",
        "            \"loss\",\n",
        "            \"count_loss\",\n",
        "            \"bin_loss\",\n",
        "            \"dist_loss\",\n",
        "            \"los_loss\",\n",
        "            \"diag_loss\",\n",
        "            \"proc_loss\",\n",
        "            \"icpc_loss\",\n",
        "            \"accuracy\",\n",
        "            \"precision\",\n",
        "            \"recall\",\n",
        "            \"F1_gpt\",\n",
        "            \"acc_gpt\",\n",
        "            \"F1_dist\",\n",
        "            \"F1_los\",\n",
        "            \"auc_roc\",\n",
        "            \"r2_count\",\n",
        "            \"F1_count\",\n",
        "            \"spearman_count\",\n",
        "            \"spearman_los\",\n",
        "            \"spearman_dist\",\n",
        "            \"pval_count\",\n",
        "            \"AUC_dist\",\n",
        "            \"auc_bin\",\n",
        "            \"mae_count\",\n",
        "            \"mae_dist\",\n",
        "            \"poisson_dev_count\",\n",
        "            \"poisson_dev_dist\",\n",
        "            \"lr\",\n",
        "        ]\n",
        "        self.track_metric_names.extend([f\"F1_dist_sep_{i}\" for i in range(6)])\n",
        "        self.track_metric_names.extend([f\"spearman_dist_sep_{i}\" for i in range(6)])\n",
        "        self.track_metric_names.extend([f\"mae_dist_sep_{i}\" for i in range(6)])\n",
        "\n",
        "        self.training_metrics = {k: [] for k in self.track_metric_names}\n",
        "        self.validation_metrics = {k: [] for k in self.track_metric_names}\n",
        "\n",
        "        self.epoch_log_variables = {\n",
        "            \"y_outcomes\": [],\n",
        "            \"y_los\": [],\n",
        "            \"y_dist_preds\": [],\n",
        "            \"y_count_preds\": [],\n",
        "            \"y_los_preds\": [],\n",
        "        }\n",
        "        # count the number of trainable parameters in the model\n",
        "        count_parameters(model)\n",
        "\n",
        "    def _init_training_metrics(self):\n",
        "        for k, _ in self.training_metrics.items():\n",
        "            self.training_metrics[k] = []\n",
        "\n",
        "    def _init_validation_metrics(self):\n",
        "        for k, _ in self.validation_metrics.items():\n",
        "            self.validation_metrics[k] = []\n",
        "\n",
        "    def get_score_checkpoint(self, epoch, val_loss):\n",
        "        \"\"\"Retrieves the path to a checkpoint file.\"\"\"\n",
        "        # name = f\"model_{epoch}_score={val_loss:4f}.pth\"\n",
        "        name = \"model.pth\"\n",
        "        return os.path.join(self.cfg.PATHS.MODEL_OUT_DIR, name)\n",
        "\n",
        "    def save_checkpoint(self, epoch, val_loss):\n",
        "        \"\"\"Saves a checkpoint.\"\"\"\n",
        "        sd = self.model.state_dict()\n",
        "        # Record the state\n",
        "        checkpoint = {\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state\": sd,\n",
        "            \"optimizer_state\": self.optimizer.state_dict(),\n",
        "            \"cfg\": self.cfg.dump(),\n",
        "        }\n",
        "        # Write the checkpoint\n",
        "        checkpoint_file = self.get_score_checkpoint(epoch, val_loss)\n",
        "        # print(f\"saving to {checkpoint_file}\")\n",
        "        torch.save(checkpoint, checkpoint_file)\n",
        "        return checkpoint_file\n",
        "\n",
        "    def get_best_score_checkpoint_path(self):\n",
        "        \"\"\"\n",
        "        Retrieves the checkpoint with lowest loss score.\n",
        "        Note: this method is sensitive to the model filename format\n",
        "        \"\"\"\n",
        "        checkpoint_dir = self.cfg.PATHS.MODEL_OUT_DIR\n",
        "        # Checkpoint file names are in lexicographic order\n",
        "        checkpoints = [f for f in os.listdir(checkpoint_dir) if \".pth\" in f]\n",
        "        # best_checkpoint_val_loss = [\n",
        "        #     float(\".\".join(x.split(\"=\")[1].split(\".\")[0:2])) for x in checkpoints\n",
        "        # ]\n",
        "        # best_idx = np.array(best_checkpoint_val_loss).argmin()\n",
        "        # name = checkpoints[best_idx]\n",
        "        name = checkpoints[0]\n",
        "        return os.path.join(checkpoint_dir, name)\n",
        "\n",
        "    def load_checkpoint_from_path(self, model_path, load_optimizer=False):\n",
        "        \"\"\"Loads the checkpoint from the given file.\"\"\"\n",
        "        # Load the checkpoint on CPU to avoid GPU mem spike\n",
        "        checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
        "        # Account for the DDP wrapper in the multi-gpu setting\n",
        "        self.model.load_state_dict(checkpoint[\"model_state\"])\n",
        "        # Load the optimizer state (commonly not done when fine-tuning)\n",
        "        if load_optimizer:\n",
        "            self.optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
        "\n",
        "        return checkpoint[\"epoch\"]\n",
        "\n",
        "    def load_best_score_checkpoint(self, load_optimizer=False):\n",
        "        \"\"\"Loads the checkpoint from the given file.\"\"\"\n",
        "        checkpoint_file_path = self.get_best_score_checkpoint_path()\n",
        "        return self.load_checkpoint_from_path(checkpoint_file_path)\n",
        "\n",
        "    def _prepare_batch(self, batch):\n",
        "        \"places the input tensors in the appropriate gpu device\"\n",
        "        device_batch = {}\n",
        "        for k, v in batch.items():\n",
        "            device_batch[k] = v.to(self.device, non_blocking=True)\n",
        "        return device_batch\n",
        "\n",
        "    def run_epoch(self, split, dataloader, epoch_count=0):\n",
        "        \"to be overloaded in the child classes\"\n",
        "        return {}\n",
        "\n",
        "    def plot_prediction_diagnostics(self, prefix=\"val\"):\n",
        "        \"Plots the histogram and scatter plots of the predicted vs true count values\"\n",
        "\n",
        "        from scipy.stats import poisson\n",
        "\n",
        "        if not os.path.isdir(os.path.join(self.cfg.PATHS.OUT_DIR, \"predictions\")):\n",
        "            os.mkdir(os.path.join(self.cfg.PATHS.OUT_DIR, \"predictions\"))\n",
        "\n",
        "        pred_fig_save_path = os.path.join(\n",
        "            self.cfg.PATHS.OUT_DIR,\n",
        "            \"predictions\",\n",
        "            f\"predictions_{prefix}.png\",\n",
        "        )\n",
        "        box_fig_save_path = os.path.join(\n",
        "            self.cfg.PATHS.OUT_DIR,\n",
        "            \"predictions\",\n",
        "            f\"box_plot_{prefix}.png\",\n",
        "        )\n",
        "        pred_save_path = os.path.join(\n",
        "            self.cfg.PATHS.OUT_DIR,\n",
        "            \"predictions\",\n",
        "            f\"predictions_{prefix}.feather\",\n",
        "        )\n",
        "        pred_df = pd.DataFrame(self.epoch_log_variables)\n",
        "        pred_df.to_feather(pred_save_path)\n",
        "\n",
        "        y_count_pred = np.array(self.epoch_log_variables[\"y_count_preds\"])\n",
        "        y_count = np.array(self.epoch_log_variables[\"y_outcomes\"])[:, 0]\n",
        "\n",
        "        sample_indices = np.random.choice(y_count.shape[0], size=1000)\n",
        "        x_poiss = np.arange(0, self.cfg.MODEL.TOP_CAP, 1)\n",
        "        with plt.style.context(PLOT_STYLE):\n",
        "            # plot training curves\n",
        "            fig, ax = plt.subplots(\n",
        "                nrows=1, ncols=2, figsize=(14, 4), constrained_layout=True\n",
        "            )\n",
        "\n",
        "            for idx in sample_indices:\n",
        "                lamb = y_count_pred[idx]\n",
        "                y = poisson.pmf(x_poiss, mu=lamb)\n",
        "                ax.flat[0].plot(x_poiss, y, alpha=0.05, color=\"r\")\n",
        "            # ax.flat[0].hist(y_count_pred, label=\"Predicted Counts\", alpha=0.6)\n",
        "            ax.flat[0].hist(\n",
        "                y_count,\n",
        "                label=\"True Counts\",\n",
        "                alpha=0.6,\n",
        "                color=\"b\",\n",
        "                density=True,\n",
        "                bins=self.cfg.MODEL.TOP_CAP,\n",
        "            )\n",
        "            ax.flat[0].set_xlabel(\"No. of Visits\")\n",
        "            ax.flat[0].set_ylabel(\"Count\")\n",
        "            ax.flat[0].set_title(\"Histogram of Predicted and True Visits\")\n",
        "            ax.flat[0].legend()\n",
        "\n",
        "            ax.flat[1].scatter(\n",
        "                x=y_count_pred[sample_indices],\n",
        "                y=y_count[sample_indices],\n",
        "                alpha=0.7,\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[1].set_xlabel(\"Predicted Visits\")\n",
        "            ax.flat[1].set_ylabel(\"True Visits\")\n",
        "            ax.flat[1].set_title(\"True vs Predicted No. of Visits\")\n",
        "\n",
        "            fig.savefig(pred_fig_save_path)\n",
        "\n",
        "        ### box plot to visualize the predictions according to risk groups\n",
        "        # break predictions into 10 groups\n",
        "        y_count_pred_bin = pd.cut(\n",
        "            y_count_pred, bins=np.linspace(0, self.cfg.MODEL.TOP_CAP, num=10)\n",
        "        )\n",
        "        box_cats = []\n",
        "        box_labels = []\n",
        "\n",
        "        for i in y_count_pred_bin.categories:\n",
        "            idxs = y_count_pred_bin == i\n",
        "            box_cats.append(y_count[idxs])\n",
        "            box_labels.append(str(i))\n",
        "\n",
        "        with plt.style.context(PLOT_STYLE):\n",
        "            fig1, ax = plt.subplots(\n",
        "                nrows=1, ncols=1, figsize=(8, 5), constrained_layout=True\n",
        "            )\n",
        "\n",
        "            medianprops = dict(linestyle=\"-.\", linewidth=2.5, color=\"firebrick\")\n",
        "            bplot = ax.boxplot(\n",
        "                box_cats, labels=box_labels, patch_artist=True, medianprops=medianprops\n",
        "            )\n",
        "            # fill with colors\n",
        "            for patch in bplot[\"boxes\"]:\n",
        "                patch.set_facecolor(\"pink\")\n",
        "\n",
        "            ax.set_xlabel(\"Predicted Category\")\n",
        "            ax.set_ylabel(\"True Visits\")\n",
        "            ax.set_title(\"Prediction Distribution in Categories\")\n",
        "            xtickNames = plt.setp(ax, xticklabels=box_labels)\n",
        "            plt.setp(xtickNames, rotation=45, fontsize=8)\n",
        "            fig1.savefig(box_fig_save_path)\n",
        "\n",
        "    def plot_grad_flow(self, epoch_number=0):\n",
        "        \"\"\"Plots the gradients flowing through different layers in the net during training.\n",
        "        Can be used for checking for possible gradient vanishing / exploding problems.\n",
        "\n",
        "        Usage: Plug this function in Trainer class after loss.backwards() as\n",
        "        \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow\"\"\"\n",
        "        # ref: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/10\n",
        "\n",
        "        if not os.path.isdir(os.path.join(self.cfg.PATHS.OUT_DIR, \"gradient_flow\")):\n",
        "            os.mkdir(os.path.join(self.cfg.PATHS.OUT_DIR, \"gradient_flow\"))\n",
        "\n",
        "        gradflow_fig_save_path = os.path.join(\n",
        "            self.cfg.PATHS.OUT_DIR,\n",
        "            \"gradient_flow\",\n",
        "            f\"gradient_flow_ep{epoch_number}.png\",\n",
        "        )\n",
        "        named_parameters = self.model.named_parameters()\n",
        "        ave_grads = []\n",
        "        max_grads = []\n",
        "        layers = []\n",
        "        for n, p in named_parameters:\n",
        "            if (p.requires_grad) and (p.grad is not None) and (\"bias\" not in n):\n",
        "                layers.append(n)\n",
        "                ave_grads.append(p.grad.abs().mean())\n",
        "                max_grads.append(p.grad.abs().max())\n",
        "        plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
        "        plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
        "        plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color=\"k\")\n",
        "        plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
        "        plt.xlim(left=0, right=len(ave_grads))\n",
        "        plt.ylim(bottom=-0.001, top=0.02)  # zoom in on the lower gradient regions\n",
        "        plt.xlabel(\"Layers\")\n",
        "        plt.ylabel(\"average gradient\")\n",
        "        plt.title(\"Gradient flow\")\n",
        "        plt.grid(True)\n",
        "        plt.legend(\n",
        "            [\n",
        "                Line2D([0], [0], color=\"c\", lw=4),\n",
        "                Line2D([0], [0], color=\"b\", lw=4),\n",
        "                Line2D([0], [0], color=\"k\", lw=4),\n",
        "            ],\n",
        "            [\"max-gradient\", \"mean-gradient\", \"zero-gradient\"],\n",
        "        )\n",
        "        plt.savefig(gradflow_fig_save_path, bbox_inches=\"tight\")\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        loss_fig_save_path = os.path.join(self.cfg.PATHS.OUT_DIR, \"training_losses.png\")\n",
        "\n",
        "        with plt.style.context(PLOT_STYLE):\n",
        "            # plot training curves\n",
        "            fig, ax = plt.subplots(\n",
        "                nrows=2, ncols=2, figsize=(14, 8), constrained_layout=True\n",
        "            )\n",
        "            steps_grid = np.arange(len(self.training_metrics[\"lr\"])) + 1\n",
        "\n",
        "            x_grid = np.arange(len(self.training_metrics[\"loss\"])) + 1\n",
        "            min_loss_at = np.argmin(np.array(self.validation_metrics[\"loss\"]))\n",
        "\n",
        "            ax.flat[0].plot(\n",
        "                x_grid, self.validation_metrics[\"loss\"], label=\"Val Loss\", marker=\"o\"\n",
        "            )\n",
        "            ax.flat[0].plot(\n",
        "                x_grid, self.training_metrics[\"loss\"], label=\"Train Loss\", marker=\"o\"\n",
        "            )\n",
        "            ax.flat[0].axvline(min_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[0].set_xlabel(\"Epochs\")\n",
        "            ax.flat[0].set_ylabel(\"Loss\")\n",
        "            ax.flat[0].set_title(\"Total Loss Curve\")\n",
        "            ax.flat[0].legend()\n",
        "\n",
        "            min_dist_loss_at = np.argmin(np.array(self.validation_metrics[\"los_loss\"]))\n",
        "            ax.flat[1].plot(\n",
        "                x_grid,\n",
        "                self.validation_metrics[\"los_loss\"],\n",
        "                label=\"Val. LOS Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[1].plot(\n",
        "                x_grid,\n",
        "                self.training_metrics[\"los_loss\"],\n",
        "                label=\"Train LOS Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[1].axvline(min_dist_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[1].set_xlabel(\"Epochs\")\n",
        "            ax.flat[1].set_ylabel(\"Loss\")\n",
        "            ax.flat[1].set_title(\"LOS Loss Curve\")\n",
        "            ax.flat[1].legend()\n",
        "\n",
        "            min_dist_loss_at = np.argmin(np.array(self.validation_metrics[\"dist_loss\"]))\n",
        "            ax.flat[2].plot(\n",
        "                x_grid,\n",
        "                self.validation_metrics[\"dist_loss\"],\n",
        "                label=\"Val Dist. Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[2].plot(\n",
        "                x_grid,\n",
        "                self.training_metrics[\"dist_loss\"],\n",
        "                label=\"Train Dist. Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[2].axvline(min_dist_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[2].set_xlabel(\"Epochs\")\n",
        "            ax.flat[2].set_ylabel(\"Loss\")\n",
        "            ax.flat[2].set_title(\"Dist Loss Curve\")\n",
        "            ax.flat[2].legend()\n",
        "\n",
        "            min_count_loss_at = np.argmin(\n",
        "                np.array(self.validation_metrics[\"count_loss\"])\n",
        "            )\n",
        "            ax.flat[3].plot(\n",
        "                x_grid,\n",
        "                self.validation_metrics[\"count_loss\"],\n",
        "                label=\"Val Count Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[3].plot(\n",
        "                x_grid,\n",
        "                self.training_metrics[\"count_loss\"],\n",
        "                label=\"Train Count Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[3].axvline(min_count_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[3].set_xlabel(\"Epochs\")\n",
        "            ax.flat[3].set_ylabel(\"Loss\")\n",
        "            ax.flat[3].set_title(\"Count Loss Curve\")\n",
        "            ax.flat[3].legend()\n",
        "\n",
        "            fig.savefig(loss_fig_save_path)\n",
        "\n",
        "    def compute_dist_metrics(self, log_variables: dict):\n",
        "        \"Note: log_variables is available from state, passing in dummy arg for clarity\"\n",
        "\n",
        "        return_dict = {}\n",
        "        if (\n",
        "            self.epoch_log_variables[\"y_dist_preds\"]\n",
        "            and self.epoch_log_variables[\"y_outcomes\"]\n",
        "        ):\n",
        "            y_count_pred = np.array(self.epoch_log_variables[\"y_count_preds\"])\n",
        "            y_count_pred_thresh = (y_count_pred > 6).astype(np.int16)\n",
        "            y_dist_pred_cnt = np.array(self.epoch_log_variables[\"y_dist_preds\"])\n",
        "            y_dist_pred_thresh = (y_dist_pred_cnt > 0).astype(np.int16)\n",
        "            y_los_pred = np.array(self.epoch_log_variables[\"y_los_preds\"]).ravel()\n",
        "            y_los_pred_thresh = (y_los_pred > 1).astype(np.int16)\n",
        "\n",
        "            y_count = np.array(self.epoch_log_variables[\"y_outcomes\"])[:, 0]\n",
        "            y_dist = np.array(self.epoch_log_variables[\"y_outcomes\"])[:, 1:]\n",
        "            y_los = np.array(self.epoch_log_variables[\"y_los\"])\n",
        "            y_dist_thresh = (y_dist > 0).astype(np.int16)\n",
        "            y_count_thresh = (y_count > 6).astype(np.int16)\n",
        "            y_los_thresh = (y_los > 1).astype(np.int16)\n",
        "\n",
        "            # count metrics (regression)\n",
        "            print(y_count_pred.max())\n",
        "            r2_score_count = r2_score(y_count, y_count_pred)\n",
        "            f1_score_count = f1_score(y_count_thresh, y_count_pred_thresh)\n",
        "\n",
        "            spearman_count, pval = stats.spearmanr(y_count, y_count_pred)\n",
        "            mae_count = mean_absolute_error(y_count, y_count_pred)\n",
        "\n",
        "            # dist metrics (binary classification)\n",
        "            mae_sep = []\n",
        "            spearman_dist_sep = []\n",
        "            for i in range(6):\n",
        "                mae_sep.append(mean_absolute_error(y_dist[:, i], y_dist_pred_cnt[:, i]))\n",
        "                spearman_dist, _ = stats.spearmanr(y_dist[:, i], y_dist_pred_cnt[:, i])\n",
        "                spearman_dist_sep.append(\n",
        "                    # f1_score(y_dist_thresh[:, i], y_dist_pred_thresh[:, i])\n",
        "                    spearman_dist\n",
        "                )\n",
        "\n",
        "            spearman_dist = np.array(spearman_dist_sep).mean()\n",
        "            mae_dist = np.array(mae_sep).mean()\n",
        "\n",
        "            # los classification\n",
        "            # print(y_los)\n",
        "            # print(y_los_pred)\n",
        "            # f1_los = f1_score(y_los_thresh, y_los_pred_thresh)\n",
        "            spearman_los, _ = stats.spearmanr(y_los, y_los_pred)\n",
        "\n",
        "            return_dict = {\n",
        "                \"r2_count\": r2_score_count,\n",
        "                \"F1_count\": f1_score_count,\n",
        "                \"mae_count\": mae_count,\n",
        "                \"spearman_count\": spearman_count,\n",
        "                \"pval_count\": pval,\n",
        "                \"spearman_dist\": spearman_dist,\n",
        "                \"mae_dist\": mae_dist,\n",
        "                \"spearman_los\": spearman_los,\n",
        "            }\n",
        "\n",
        "            return_dict.update({f\"mae_dist_sep_{i}\": mae_sep[i] for i in range(6)})\n",
        "            return_dict.update(\n",
        "                {f\"spearman_dist_sep_{i}\": spearman_dist_sep[i] for i in range(6)}\n",
        "            )\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "    def fit(self):\n",
        "        model, cfg = self.model, self.cfg\n",
        "        raw_model = model.module if hasattr(self.model, \"module\") else model\n",
        "        self.optimizer, self.scheduler = raw_model.configure_optimizers(cfg)\n",
        "\n",
        "        best_loss = float(\"inf\")\n",
        "        self._init_training_metrics()\n",
        "        self._init_validation_metrics()\n",
        "        for epoch_count in range(cfg.OPTIM.MAX_EPOCHS):\n",
        "            train_epoch_metrics = self.run_epoch(\n",
        "                \"train\", self.train_dataloader, epoch_count\n",
        "            )\n",
        "            # self.plot_grad_flow(epoch_count)\n",
        "\n",
        "            # scheduler step for 1cycle is done within run_epoch\n",
        "            if self.cfg.OPTIM.LR_POLICY not in [\"1cycle\"]:\n",
        "                self.scheduler.step()\n",
        "\n",
        "            val_epoch_metrics = self.run_epoch(\n",
        "                \"validation\", self.val_dataloader, epoch_count\n",
        "            )\n",
        "            # append the epoch metric into\n",
        "            for k, v in train_epoch_metrics.items():\n",
        "                self.training_metrics[k].append(v)\n",
        "            for k, v in val_epoch_metrics.items():\n",
        "                self.validation_metrics[k].append(v)\n",
        "\n",
        "            val_loss = val_epoch_metrics[\"loss\"]\n",
        "            # supports early stopping based on the test loss, or just save always if no test set is provided\n",
        "            is_good_model = val_loss < best_loss\n",
        "            if is_good_model:\n",
        "                best_loss = val_loss\n",
        "                self.best_epoch = epoch_count\n",
        "                self.save_checkpoint(epoch_count, val_loss)\n",
        "\n",
        "        self.plot_training_curves()\n",
        "        print(f\"Experiment logs stored at: {cfg.PATHS.OUT_DIR}\")\n",
        "\n",
        "        return best_loss\n",
        "\n",
        "    def predict(self):\n",
        "        print(\"=\" * 100)\n",
        "        best_epoch = self.load_best_score_checkpoint()\n",
        "        print(f\"loaded model from epoch: {best_epoch}\")\n",
        "\n",
        "        _ = self.run_epoch(\"validation\", self.val_dataloader)\n",
        "        self.plot_prediction_diagnostics(prefix=\"val\")\n",
        "\n",
        "        # get test_loss\n",
        "        test_epoch_metrics_l = []\n",
        "        for i, test_loader in enumerate(self.test_dataloaders):\n",
        "            test_epoch_metrics = self.run_epoch(\"test\", test_loader)\n",
        "            test_epoch_metrics_l.append(test_epoch_metrics)\n",
        "            self.plot_prediction_diagnostics(prefix=f\"test_{i}\")\n",
        "\n",
        "        return test_epoch_metrics_l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQZOCVvVz0x4"
      },
      "source": [
        "**MIMIC Trainer**\n",
        "  * Extends the functionality of the BaseTrainer class, providing tailored methods for training, evaluation, and visualization in medical data scenarios. It includes features such as initializing log variables, plotting training curves, computing distribution metrics, running epochs, and making predictions based on the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq8gWUnLz5q2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from matplotlib.pyplot import Line2D\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    cohen_kappa_score,\n",
        "    f1_score,\n",
        "    mean_absolute_error,\n",
        "    mean_poisson_deviance,\n",
        "    precision_score,\n",
        "    r2_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "# from trainers.base_trainer import BaseTrainer\n",
        "\n",
        "\n",
        "class Trainer_MIMIC(BaseTrainer):\n",
        "    def __init__(self, cfg, model, train_dataloader, val_dataloader, test_dataloaders):\n",
        "        super().__init__(cfg, model, train_dataloader, val_dataloader, test_dataloaders)\n",
        "\n",
        "        self.epoch_log_variables = {\n",
        "            \"y_outcomes\": [],\n",
        "            \"y_los\": [],\n",
        "            \"y_bin_preds\": [],\n",
        "            \"y_los_preds\": [],\n",
        "        }\n",
        "\n",
        "    def _init_log_variables(self):\n",
        "        for k, _ in self.epoch_log_variables.items():\n",
        "            self.epoch_log_variables[k] = []\n",
        "\n",
        "    def plot_training_curves(self):\n",
        "        loss_fig_save_path = os.path.join(self.cfg.PATHS.OUT_DIR, \"training_losses.png\")\n",
        "\n",
        "        with plt.style.context(\"seaborn-muted\"):\n",
        "            # plot training curves\n",
        "            fig, ax = plt.subplots(\n",
        "                nrows=2, ncols=2, figsize=(14, 8), constrained_layout=True\n",
        "            )\n",
        "            steps_grid = np.arange(len(self.training_metrics[\"lr\"])) + 1\n",
        "\n",
        "            x_grid = np.arange(len(self.training_metrics[\"loss\"])) + 1\n",
        "            min_loss_at = np.argmin(np.array(self.validation_metrics[\"loss\"]))\n",
        "\n",
        "            ax.flat[0].plot(\n",
        "                x_grid, self.validation_metrics[\"loss\"], label=\"Val Loss\", marker=\"o\"\n",
        "            )\n",
        "            ax.flat[0].plot(\n",
        "                x_grid, self.training_metrics[\"loss\"], label=\"Train Loss\", marker=\"o\"\n",
        "            )\n",
        "            ax.flat[0].axvline(min_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[0].set_xlabel(\"Epochs\")\n",
        "            ax.flat[0].set_ylabel(\"Loss\")\n",
        "            ax.flat[0].set_title(\"Total Loss Curve\")\n",
        "            ax.flat[0].legend()\n",
        "\n",
        "            min_loss_at = np.argmin(np.array(self.validation_metrics[\"los_loss\"]))\n",
        "\n",
        "            ax.flat[2].plot(\n",
        "                x_grid,\n",
        "                self.validation_metrics[\"los_loss\"],\n",
        "                label=\"Val Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[2].plot(\n",
        "                x_grid,\n",
        "                self.training_metrics[\"los_loss\"],\n",
        "                label=\"Train Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[2].axvline(min_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[2].set_xlabel(\"Epochs\")\n",
        "            ax.flat[2].set_ylabel(\"Loss\")\n",
        "            ax.flat[2].set_title(\"LoS Loss Curve\")\n",
        "            ax.flat[2].legend()\n",
        "\n",
        "            min_loss_at = np.argmin(np.array(self.validation_metrics[\"bin_loss\"]))\n",
        "\n",
        "            ax.flat[3].plot(\n",
        "                x_grid,\n",
        "                self.validation_metrics[\"bin_loss\"],\n",
        "                label=\"Val Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[3].plot(\n",
        "                x_grid,\n",
        "                self.training_metrics[\"bin_loss\"],\n",
        "                label=\"Train Loss\",\n",
        "                marker=\"o\",\n",
        "            )\n",
        "            ax.flat[3].axvline(min_loss_at + 1, linestyle=\"--\", label=\"Min Loss\")\n",
        "            ax.flat[3].set_xlabel(\"Epochs\")\n",
        "            ax.flat[3].set_ylabel(\"Loss\")\n",
        "            ax.flat[3].set_title(\"Bin. Loss Curve\")\n",
        "            ax.flat[3].legend()\n",
        "\n",
        "            fig.savefig(loss_fig_save_path)\n",
        "\n",
        "        return\n",
        "\n",
        "    def compute_dist_metrics(self, log_variables: dict):\n",
        "        \"Note: log_variables is available from state, passing in dummy arg for clarity\"\n",
        "        # override base trainer\n",
        "\n",
        "        return_dict = {}\n",
        "\n",
        "        y_bin_pred = np.array(self.epoch_log_variables[\"y_bin_preds\"])\n",
        "        y_bin_pred_thresh = (y_bin_pred > 0.5).astype(np.int8)\n",
        "        y_bin_true = np.array(self.epoch_log_variables[\"y_outcomes\"])\n",
        "\n",
        "        y_los_pred = np.array(self.epoch_log_variables[\"y_los_preds\"])\n",
        "        y_los_true = np.array(self.epoch_log_variables[\"y_los\"])\n",
        "\n",
        "        # metrics\n",
        "        auc_bin = roc_auc_score(y_bin_true, y_bin_pred)\n",
        "\n",
        "        spearman_los, _ = stats.spearmanr(y_los_true, y_los_pred)\n",
        "        # r2_los = r2_score(y_los_true, y_los_pred)\n",
        "\n",
        "        return_dict = {\n",
        "            \"auc_bin\": auc_bin,\n",
        "            \"spearman_los\": spearman_los,\n",
        "        }\n",
        "\n",
        "        return return_dict\n",
        "\n",
        "    def run_epoch(self, split, dataloader, epoch_count=0):\n",
        "        assert split.lower() in (\"train\", \"validation\", \"test\")\n",
        "\n",
        "        self._init_log_variables()\n",
        "\n",
        "        is_train = True if split.lower() == \"train\" else False\n",
        "        self.model.train(is_train)\n",
        "\n",
        "        lr = 0.0\n",
        "        losses = []\n",
        "        bin_losses = []\n",
        "        los_losses = []\n",
        "        pbar = (\n",
        "            tqdm(enumerate(dataloader), total=len(dataloader))\n",
        "            if is_train\n",
        "            else enumerate(dataloader)\n",
        "        )\n",
        "        self.model.zero_grad()\n",
        "        acc_steps = self.cfg.MODEL.ACCU_GRAD_STEPS\n",
        "        for it, batch in pbar:\n",
        "            # place data on the correct device\n",
        "            batch_dict = self._prepare_batch(batch)\n",
        "            # forward the model\n",
        "            with torch.set_grad_enabled(is_train):\n",
        "                with autocast(enabled=self.cfg.USE_AMP):\n",
        "                    (\n",
        "                        loss,\n",
        "                        bin_loss,\n",
        "                        los_loss,\n",
        "                        y_pred_bin,\n",
        "                        y_los_pred,\n",
        "                        y_los_true,\n",
        "                        patient_vec,\n",
        "                    ) = self.model(**batch_dict)\n",
        "            report_loss = loss\n",
        "            if is_train:\n",
        "                loss = loss / acc_steps\n",
        "                # backprop and update the parameters\n",
        "                self.grad_scaler.scale(loss).backward()\n",
        "                if (it + 1) % self.cfg.MODEL.ACCU_GRAD_STEPS == 0:\n",
        "                    self.grad_scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_value_(\n",
        "                        self.model.parameters(), self.cfg.OPTIM.GRAD_CLIP_T\n",
        "                    )\n",
        "                    self.grad_scaler.step(self.optimizer)\n",
        "                    self.grad_scaler.update()\n",
        "                    self.model.zero_grad()\n",
        "\n",
        "                    lr = 0.0\n",
        "                    for param_group in self.optimizer.param_groups:\n",
        "                        lr = param_group[\"lr\"]\n",
        "\n",
        "                    if self.cfg.OPTIM.LR_POLICY in [\"1cycle\"]:\n",
        "                        self.scheduler.step()\n",
        "                    self.training_metrics[\"lr\"].append(lr)\n",
        "\n",
        "                # report progress\n",
        "                pbar.set_description(\n",
        "                    f\"epoch {epoch_count + 1} iter {it}: train loss {loss.item() * acc_steps:.5f} lr {lr:e}\"\n",
        "                )\n",
        "\n",
        "            # store metrics for logging\n",
        "            losses.append(report_loss.item())\n",
        "            bin_losses.append(bin_loss.item())\n",
        "            los_losses.append(los_loss.item())\n",
        "\n",
        "            self.epoch_log_variables[\"y_outcomes\"].extend(\n",
        "                batch_dict[\"y_outcome\"].cpu().detach().numpy().tolist()\n",
        "            )\n",
        "            self.epoch_log_variables[\"y_los\"].extend(\n",
        "                y_los_true.cpu().detach().numpy().tolist()\n",
        "            )\n",
        "            self.epoch_log_variables[\"y_bin_preds\"].extend(\n",
        "                y_pred_bin.cpu().detach().numpy().tolist()\n",
        "            )\n",
        "            self.epoch_log_variables[\"y_los_preds\"].extend(\n",
        "                y_los_pred.cpu().detach().numpy().tolist()\n",
        "            )\n",
        "\n",
        "        metrics_d = {\n",
        "            \"loss\": float(np.mean(losses)),\n",
        "            \"bin_loss\": float(np.mean(bin_losses)),\n",
        "            \"los_loss\": float(np.mean(los_losses)),\n",
        "        }\n",
        "\n",
        "        if not is_train:\n",
        "            pass\n",
        "            metrics_d.update(self.compute_dist_metrics(self.epoch_log_variables))\n",
        "\n",
        "        # compute metrics\n",
        "        print_str = f\"{split} epoch: {epoch_count+1} \"\n",
        "        for k, v in metrics_d.items():\n",
        "            print_key = str(k)\n",
        "            print_str += f\" | {print_key}: {v:.5f}\"\n",
        "\n",
        "        print(print_str)\n",
        "        print(\"=\" * 100)\n",
        "        return metrics_d\n",
        "\n",
        "    def predict(self):\n",
        "        print(\"=\" * 100)\n",
        "        best_epoch = self.load_best_score_checkpoint()\n",
        "        print(f\"loaded model from epoch: {best_epoch}\")\n",
        "\n",
        "        _ = self.run_epoch(\"validation\", self.val_dataloader)\n",
        "\n",
        "        # get test_loss\n",
        "        test_epoch_metrics_l = []\n",
        "        for i, test_loader in enumerate(self.test_dataloaders):\n",
        "            test_epoch_metrics = self.run_epoch(\"test\", test_loader)\n",
        "            test_epoch_metrics_l.append(test_epoch_metrics)\n",
        "\n",
        "        return test_epoch_metrics_l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61-Jiv0Q8nl6"
      },
      "source": [
        "**MIMIC Dataset**\n",
        "  * Represents our MIMIC dataset and handles data loading, preprocessing, and padding for sequences of medical codes and other features. The class offers methods for retrieving individual samples, handling sequence padding, and collating batches for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6yP4TaqJNup"
      },
      "outputs": [],
      "source": [
        "\"\"\"MIMIC dataset.\"\"\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# from core.config import cfg\n",
        "# from dataset.vectorizer import EHRCountVectorizer\n",
        "\n",
        "\n",
        "class MIMICDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, vec_dict):\n",
        "        self.df = df\n",
        "        self.vectorizer = vec_dict[\"mimic_all\"]\n",
        "\n",
        "        self.y_outcome = np.array(df.loc[:, \"hospital_expire_flag\"])\n",
        "        self.y_los = np.array(df.loc[:, \"los\"])\n",
        "        self.y_next_v = np.array(df.loc[:, \"days_from_prev\"])\n",
        "\n",
        "        self.icd = df.loc[:, \"icd_all\"]\n",
        "        self.proc = df.loc[:, \"proc_all\"]\n",
        "        self.drg = df.loc[:, \"drug_all\"]\n",
        "        self.service = df.loc[:, \"service_all\"]\n",
        "        self.admtype = df.loc[:, \"admission_type\"]\n",
        "        self.insur = df.loc[:, \"insurance\"]\n",
        "        self.marit = df.loc[:, \"marital_status\"]\n",
        "\n",
        "        self.delta_t = df.loc[:, \"days_from_prev\"]\n",
        "        self.language = df.loc[:, \"encoded_language\"]\n",
        "        self.ethnicity = df.loc[:, \"encoded_ethnicity\"]\n",
        "        self.language = df.loc[:, \"encoded_language\"]\n",
        "        self.gender = df.loc[:, \"encoded_gender\"]\n",
        "        self.age = df.loc[:, \"anchor_age\"]\n",
        "        self.seq_length = df.loc[:, \"seq_length\"]\n",
        "\n",
        "        self.length = self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        diag_seq, diag_n_tkns_per_visit = self.vectorizer.vectorize(self.icd[idx])\n",
        "        proc_seq, proc_n_tkns_per_visit = self.vectorizer.vectorize(self.proc[idx])\n",
        "        drg_seq, drg_n_tkns_per_visit = self.vectorizer.vectorize(self.drg[idx])\n",
        "        service, service_n_tkns_per_visit = self.vectorizer.vectorize(self.service[idx])\n",
        "        admtype, admtype_n_tkns_per_visit = self.vectorizer.vectorize(self.admtype[idx])\n",
        "\n",
        "        insur, _ = self.vectorizer.vectorize(self.insur[idx])\n",
        "        marit, _ = self.vectorizer.vectorize(self.marit[idx])\n",
        "\n",
        "        delta_t = [float(x) for x in self.delta_t[idx].split(\";\")]\n",
        "        y_los = [float(x) for x in self.y_los[idx].split(\";\")][1:]\n",
        "        x_los = [float(x) for x in self.y_los[idx].split(\";\")][:-1]\n",
        "        y_next_v = [float(x) for x in self.y_next_v[idx].split(\";\")][1:]\n",
        "        x_next_v = [float(x) for x in self.y_next_v[idx].split(\";\")][:-1]\n",
        "\n",
        "        return {\n",
        "            \"diag_seq\": diag_seq,\n",
        "            \"proc_seq\": proc_seq,\n",
        "            \"drg_seq\": drg_seq,\n",
        "            \"seq_length\": len(diag_n_tkns_per_visit),\n",
        "            \"diag_max_visit_items\": min(50, max(diag_n_tkns_per_visit)),\n",
        "            \"proc_max_visit_items\": min(40, max(proc_n_tkns_per_visit)),\n",
        "            \"drug_max_visit_items\": min(2, max(drg_n_tkns_per_visit)),\n",
        "            \"service_max_visit_items\": min(10, max(service_n_tkns_per_visit)),\n",
        "            \"admtype_max_visit_items\": min(4, max(admtype_n_tkns_per_visit)),\n",
        "            \"delta_t\": np.array(delta_t),\n",
        "            \"age\": float(self.age[idx]),\n",
        "            \"gender\": int(self.gender[idx]),\n",
        "            \"language\": int(self.language[idx]),\n",
        "            \"ethnicity\": int(self.ethnicity[idx]),\n",
        "            \"service\": service,\n",
        "            \"admtype\": admtype,\n",
        "            \"insurance\": np.array(insur).ravel(),\n",
        "            \"marit\": np.array(marit).ravel(),\n",
        "            \"y_outcome\": int(self.y_outcome[idx]),\n",
        "            \"y_los\": np.array(y_los),\n",
        "            \"y_next_v\": np.array(y_next_v),\n",
        "            \"x_los\": np.array(x_los),\n",
        "            \"x_next_v\": np.array(x_next_v),\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    @staticmethod\n",
        "    def pad_sequence(seq, max_num_visits, max_max_visit_items):\n",
        "        time_pad = max_num_visits - len(seq)\n",
        "        if time_pad < 0:\n",
        "            breakpoint()\n",
        "        seq = [np.array(xi) for xi in seq]\n",
        "        padded_seq = []\n",
        "        for i, visit in enumerate(seq):\n",
        "            # some visits are longer than hardcoded max visit lens,\n",
        "            # we just ignore the other tokens\n",
        "            if len(visit) < max_max_visit_items:\n",
        "                visit_idx = np.arange(len(visit)).astype(np.int16)\n",
        "            else:\n",
        "                visit_idx = np.random.choice(\n",
        "                    np.arange(len(visit)).astype(np.int16),\n",
        "                    size=max_max_visit_items,\n",
        "                    replace=False,\n",
        "                )\n",
        "            visit_tr = visit[visit_idx]\n",
        "            intra_pad = max_max_visit_items - visit_tr.shape[0]\n",
        "            padded_seq.append(np.pad(visit_tr, pad_width=(0, intra_pad)))\n",
        "\n",
        "        # now pad along time axis\n",
        "        padded_seq = np.pad(np.stack(padded_seq), pad_width=((0, time_pad), (0, 0)))\n",
        "        return torch.tensor(padded_seq, dtype=torch.long)\n",
        "\n",
        "    @staticmethod\n",
        "    def collate_fn(batch, is_flat_seq=False):\n",
        "        keys = list(batch[0].keys())\n",
        "        processed_batch = {k: [] for k in keys}\n",
        "\n",
        "        # all 1-D sequences that need padding\n",
        "        single_pad_visit_cols = [\n",
        "            \"insurance\",\n",
        "            \"marit\",\n",
        "            \"delta_t\",\n",
        "            \"y_los\",\n",
        "            \"y_next_v\",\n",
        "            \"x_los\",\n",
        "            \"x_next_v\",\n",
        "        ]\n",
        "        seq_keys = single_pad_visit_cols + [\n",
        "            \"diag_seq\",\n",
        "            \"proc_seq\",\n",
        "            \"drg_seq\",\n",
        "            \"service\",\n",
        "            \"admtype\",\n",
        "        ]\n",
        "        float_cols = [\"age\", \"delta_t\", \"y_los\", \"y_next_v\", \"x_los\", \"x_next_v\"]\n",
        "\n",
        "        # processing all keys except seq_keys\n",
        "        for _, sample in enumerate(batch):\n",
        "            for col, v in sample.items():\n",
        "                if col not in seq_keys:\n",
        "                    processed_batch[col].append(v)\n",
        "\n",
        "        max_num_visits = max(processed_batch[\"seq_length\"])\n",
        "        diag_max_max_visit_items = max(processed_batch[\"diag_max_visit_items\"])\n",
        "        proc_max_max_visit_items = max(processed_batch[\"proc_max_visit_items\"])\n",
        "        drug_max_max_visit_items = max(processed_batch[\"drug_max_visit_items\"])\n",
        "        service_max_max_visit_items = max(processed_batch[\"service_max_visit_items\"])\n",
        "        admtype_max_max_visit_items = max(processed_batch[\"admtype_max_visit_items\"])\n",
        "\n",
        "        processed_batch.pop(\"diag_max_visit_items\")\n",
        "        processed_batch.pop(\"proc_max_visit_items\")\n",
        "        processed_batch.pop(\"drug_max_visit_items\")\n",
        "        processed_batch.pop(\"service_max_visit_items\")\n",
        "        processed_batch.pop(\"admtype_max_visit_items\")\n",
        "\n",
        "        # processing seq_keys\n",
        "        for _, sample in enumerate(batch):\n",
        "            padded_diag_seq = MIMICDataset.pad_sequence(\n",
        "                sample[\"diag_seq\"], max_num_visits, diag_max_max_visit_items\n",
        "            )\n",
        "            processed_batch[\"diag_seq\"].append(padded_diag_seq.unsqueeze(0))\n",
        "            padded_proc_seq = MIMICDataset.pad_sequence(\n",
        "                sample[\"proc_seq\"], max_num_visits, proc_max_max_visit_items\n",
        "            )\n",
        "            processed_batch[\"proc_seq\"].append(padded_proc_seq.unsqueeze(0))\n",
        "            padded_drg_seq = MIMICDataset.pad_sequence(\n",
        "                sample[\"drg_seq\"], max_num_visits, drug_max_max_visit_items\n",
        "            )\n",
        "            processed_batch[\"drg_seq\"].append(padded_drg_seq.unsqueeze(0))\n",
        "            padded_service_seq = MIMICDataset.pad_sequence(\n",
        "                sample[\"service\"], max_num_visits, service_max_max_visit_items\n",
        "            )\n",
        "            processed_batch[\"service\"].append(padded_service_seq.unsqueeze(0))\n",
        "            padded_admtype_seq = MIMICDataset.pad_sequence(\n",
        "                sample[\"admtype\"], max_num_visits, admtype_max_max_visit_items\n",
        "            )\n",
        "            processed_batch[\"admtype\"].append(padded_admtype_seq.unsqueeze(0))\n",
        "\n",
        "            for col in single_pad_visit_cols:\n",
        "                if max_num_visits - sample[col].shape[0] < 0:\n",
        "                    breakpoint()\n",
        "                padded_col = np.pad(\n",
        "                    sample[col], pad_width=(0, max_num_visits - sample[col].shape[0])\n",
        "                )\n",
        "                processed_batch[col].append(padded_col)\n",
        "\n",
        "        processed_batch[\"y_outcome\"] = torch.LongTensor(processed_batch[\"y_outcome\"])\n",
        "        # processed_batch[\"y_los\"] = torch.FloatTensor(processed_batch[\"y_los\"])\n",
        "        processed_batch[\"gender\"] = torch.FloatTensor(processed_batch[\"gender\"])\n",
        "        processed_batch[\"seq_length\"] = torch.FloatTensor(processed_batch[\"seq_length\"])\n",
        "        processed_batch[\"ethnicity\"] = torch.FloatTensor(processed_batch[\"ethnicity\"])\n",
        "        processed_batch[\"language\"] = torch.FloatTensor(processed_batch[\"language\"])\n",
        "        processed_batch[\"age\"] = torch.FloatTensor(processed_batch[\"age\"])\n",
        "\n",
        "        processed_batch[\"diag_seq\"] = torch.cat(processed_batch[\"diag_seq\"], dim=0)\n",
        "        processed_batch[\"proc_seq\"] = torch.cat(processed_batch[\"proc_seq\"], dim=0)\n",
        "        processed_batch[\"drg_seq\"] = torch.cat(processed_batch[\"drg_seq\"], dim=0)\n",
        "        processed_batch[\"service\"] = torch.cat(processed_batch[\"service\"], dim=0)\n",
        "        processed_batch[\"admtype\"] = torch.cat(processed_batch[\"admtype\"], dim=0)\n",
        "\n",
        "        for col in single_pad_visit_cols:\n",
        "            if col in float_cols:\n",
        "                processed_batch[col] = torch.FloatTensor(processed_batch[col])\n",
        "            else:\n",
        "                processed_batch[col] = torch.LongTensor(processed_batch[col])\n",
        "        return processed_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsCfi87rHFRf"
      },
      "source": [
        "**Dataloader**\n",
        "  * Provides functions for loading and preprocessing data from the MIMIC dataset for training and testing our models. It includes functions for loading dataframes, applying preprocessing steps such as truncating sequences and capping outcomes, loading vectorizers, and constructing PyTorch dataloaders for training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoQp241vHGEW"
      },
      "outputs": [],
      "source": [
        "\"\"\"Data loader.\"\"\"\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import _pickle as pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# from core.config import cfg\n",
        "# from dataset.mimic_dataset import MIMICDataset\n",
        "# from dataset.vectorizer import EHRCountVectorizer\n",
        "# from utils import common\n",
        "\n",
        "\n",
        "def _truncate_mimic_df(df, max_seq_length):\n",
        "    \"Truncate the sequences to max_seq_length\"\n",
        "    seq_columns = [\n",
        "        \"icd_all\",\n",
        "        \"proc_all\",\n",
        "        \"drug_all\",\n",
        "        \"service_all\",\n",
        "        \"admission_type\",\n",
        "        \"insurance\",\n",
        "        \"marital_status\",\n",
        "        \"days_from_prev\",\n",
        "        \"los\",\n",
        "    ]\n",
        "\n",
        "    def _truncator(row):\n",
        "        visits = row.split(\";\")\n",
        "        trunc_visits = visits[-(max_seq_length - 1) :]\n",
        "        return \";\".join(trunc_visits)\n",
        "\n",
        "    for col in seq_columns:\n",
        "        print(col)\n",
        "        df.loc[:, col] = df.loc[:, col].apply(lambda row: _truncator(row))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def apply_topcap(row, topcap):\n",
        "    capped_outcome = []\n",
        "    for i in range(len(row)):\n",
        "        row_count = row[i]\n",
        "        row_count = min(row_count, topcap)\n",
        "        capped_outcome.append(row_count)\n",
        "    capped_outcome = (\n",
        "        [capped_outcome[0]]\n",
        "        + [capped_outcome[1] + capped_outcome[2]]\n",
        "        + capped_outcome[3:]\n",
        "    )\n",
        "    return np.array(capped_outcome)\n",
        "\n",
        "\n",
        "def load_mimic_dataframe(\n",
        "    datapath, filename, split, max_seq_length, topcap, is_sample=False, sample_pct=None\n",
        "):\n",
        "    assert split in [\"train\", \"test\"], \"split must be either 'train' or 'test'\"\n",
        "\n",
        "    datapath = './drive/MyDrive/mimic-iv-1.0/'\n",
        "    file_path = os.path.join(datapath, filename)\n",
        "    df = pd.read_feather(file_path)\n",
        "\n",
        "    # drop patients with < 3 visits\n",
        "    df = df.query(\"seq_length >= 3\")\n",
        "    df = df.query(f\"seq_length <= 1000\")\n",
        "\n",
        "    # if split == \"test\": max_seq_length = 3\n",
        "    print(f\"Using seqlength of {max_seq_length}\")\n",
        "    df = _truncate_mimic_df(df, max_seq_length)\n",
        "\n",
        "    if split == \"train\":\n",
        "        if is_sample:\n",
        "            sample_frac = 1.0 if sample_pct is None else sample_pct\n",
        "            print(f\"Using sample proportion of {sample_frac} percent\")\n",
        "            df = df.sample(frac=sample_frac, random_state=100)\n",
        "        print(\"Training: Stats\")\n",
        "        print(df.seq_length.describe())\n",
        "\n",
        "    df.reset_index(inplace=True, drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_mimic_vectorizers(cfg, df_train):\n",
        "    infile = open(\n",
        "        cfg.PATHS.VECTORIZER_PATH, \"rb\"\n",
        "    )\n",
        "    vec_dict = pickle.load(infile)\n",
        "    infile.close()\n",
        "    return vec_dict\n",
        "\n",
        "\n",
        "def get_mimic_dataloaders(cfg):\n",
        "    seed_everything(cfg.RNG_SEED)\n",
        "\n",
        "    df_train = load_mimic_dataframe(\n",
        "        datapath=cfg.PATHS.DATAPATH,\n",
        "        filename=cfg.TRAIN.FILENAME,\n",
        "        split=\"train\",\n",
        "        max_seq_length=cfg.MODEL.MAX_SEQ_LENGTH,\n",
        "        topcap=cfg.MODEL.TOP_CAP,\n",
        "        is_sample=cfg.OVERFIT_ON_BATCH,\n",
        "        sample_pct=cfg.OVERFIT_ON_BATCH_PCT,\n",
        "    )\n",
        "\n",
        "    df_test = load_mimic_dataframe(\n",
        "        datapath=cfg.PATHS.DATAPATH,\n",
        "        filename=cfg.TEST.FILENAME,\n",
        "        split=\"test\",\n",
        "        max_seq_length=cfg.MODEL.MAX_SEQ_LENGTH,\n",
        "        topcap=cfg.MODEL.TOP_CAP,\n",
        "    )\n",
        "    # optional second test set, by default copy of the first\n",
        "    df_test2 = load_mimic_dataframe(\n",
        "        datapath=cfg.PATHS.DATAPATH,\n",
        "        filename=cfg.TEST.FILENAME2,\n",
        "        split=\"test\",\n",
        "        max_seq_length=cfg.MODEL.MAX_SEQ_LENGTH,\n",
        "        topcap=cfg.MODEL.TOP_CAP,\n",
        "    )\n",
        "\n",
        "    vec_dict = load_mimic_vectorizers(cfg, df_train)\n",
        "\n",
        "    train_dataset = MIMICDataset(\n",
        "        df_train,\n",
        "        vec_dict,\n",
        "    )\n",
        "\n",
        "    test_dataset = MIMICDataset(\n",
        "        df_test,\n",
        "        vec_dict,\n",
        "    )\n",
        "\n",
        "    test_dataset2 = MIMICDataset(\n",
        "        df_test2,\n",
        "        vec_dict,\n",
        "    )\n",
        "    collate_fn = MIMICDataset.collate_fn\n",
        "\n",
        "    dataset_size = len(train_dataset)\n",
        "    indices = list(range(dataset_size))\n",
        "    split = int(np.floor(cfg.TRAIN.VALIDATION_SPLIT * dataset_size))\n",
        "    np.random.shuffle(indices)\n",
        "    train_indices, valid_indices = indices[split:], indices[:split]\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=cfg.TRAIN.BATCH_SIZE,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "        drop_last=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    val_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        sampler=valid_sampler,\n",
        "        batch_size=cfg.TEST.BATCH_SIZE,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "        drop_last=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    test_dataloader = DataLoader(\n",
        "        test_dataset,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=cfg.TEST.BATCH_SIZE,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "        drop_last=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    test_dataloader2 = DataLoader(\n",
        "        test_dataset2,\n",
        "        collate_fn=collate_fn,\n",
        "        batch_size=cfg.TEST.BATCH_SIZE,\n",
        "        num_workers=cfg.DATALOADER.NUM_WORKERS,\n",
        "        drop_last=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "\n",
        "    test_dataloaders = [test_dataloader, test_dataloader2]\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDxXDToJFQef"
      },
      "source": [
        "# Evaluation and Results\n",
        "**Running Experiments Script**\n",
        "  * This script serves as the entry point for running our experiments with different configurations on the MIMIC dataset.\n",
        "    * **Experiment Runner Function (run_experiment):**\n",
        "      * Initializes the specified model based on the configuration and the custom trainer, Trainer_MIMIC, with the model and dataloaders. It also conducts training and evaluating, logging the test results to a CSV file.\n",
        "    * **Main Function (main):**\n",
        "      * Begins by parsing command-line arguments to retrieve the configuration file path. Subsequently, it handles configuration and logging paths, sets the experiment seed, prepares dataloaders, and executes the experiment with the specified configuration. Finally, it prints the duration of the experiment execution, providing insights into its runtime.\n",
        "\n",
        "**Results after Running the Script:**\n",
        "  * These results display the training and validation metrics for each epoch during model training. For each epoch, it shows the iteration progress, indicating the current epoch, iteration number, training loss, and learning rate. The subsequent lines present the training and validation metrics, including the total loss, binary loss, and LOS (Length of Stay) loss. Additionally, it provides specific evaluation metrics such as AUC for binary classification and Spearman correlation coefficient for LOS prediction.\n",
        "  * **Note:** Some results will show as zero or nan and graphs empty because they are being used with the Pummel dataset which we do not possess.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF3zUMYDHcW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "043d353c-98b6-418d-a804-1a5c53f62ba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using seqlength of 100\n",
            "icd_all\n",
            "proc_all\n",
            "drug_all\n",
            "service_all\n",
            "admission_type\n",
            "insurance\n",
            "marital_status\n",
            "days_from_prev\n",
            "los\n",
            "Training: Stats\n",
            "count    16209.000000\n",
            "mean         7.200691\n",
            "std          7.308505\n",
            "min          3.000000\n",
            "25%          3.000000\n",
            "50%          5.000000\n",
            "75%          8.000000\n",
            "max        236.000000\n",
            "Name: seq_length, dtype: float64\n",
            "Using seqlength of 100\n",
            "icd_all\n",
            "proc_all\n",
            "drug_all\n",
            "service_all\n",
            "admission_type\n",
            "insurance\n",
            "marital_status\n",
            "days_from_prev\n",
            "los\n",
            "Using seqlength of 100\n",
            "icd_all\n",
            "proc_all\n",
            "drug_all\n",
            "service_all\n",
            "admission_type\n",
            "insurance\n",
            "marital_status\n",
            "days_from_prev\n",
            "los\n",
            "Number of steps per epoch: 406\n",
            "Total vocab size: 2668\n",
            "====================================================================================================\n",
            "Running Experiment: default_addSANS\n",
            "====================================================================================================\n",
            "+-----------------------------------------------+------------+\n",
            "|                    Modules                    | Parameters |\n",
            "+-----------------------------------------------+------------+\n",
            "|        pummel_embed.token_embed.weight        |   320160   |\n",
            "|               ethn_embed.weight               |     32     |\n",
            "| sansformer.0.sans_attention.proj_ch1.0.weight |   65536    |\n",
            "|  sansformer.0.sans_attention.proj_ch1.0.bias  |    512     |\n",
            "|  sansformer.0.sans_attention.conv_proj.weight |   40000    |\n",
            "|   sansformer.0.sans_attention.conv_proj.bias  |    200     |\n",
            "|  sansformer.0.sans_attention.proj_out.weight  |   32768    |\n",
            "|   sansformer.0.sans_attention.proj_out.bias   |    128     |\n",
            "|    sansformer.0.sans_attention.norm1.weight   |    128     |\n",
            "|     sansformer.0.sans_attention.norm1.bias    |    128     |\n",
            "|    sansformer.0.sans_attention.norm2.weight   |    256     |\n",
            "|     sansformer.0.sans_attention.norm2.bias    |    256     |\n",
            "|    sansformer.0.sans_attention.norm3.weight   |    128     |\n",
            "|     sansformer.0.sans_attention.norm3.bias    |    128     |\n",
            "|           sansformer.0.norm1.weight           |    128     |\n",
            "|            sansformer.0.norm1.bias            |    128     |\n",
            "|           sansformer.0.norm2.weight           |    128     |\n",
            "|            sansformer.0.norm2.bias            |    128     |\n",
            "|            sansformer.0.ff.0.weight           |   65536    |\n",
            "|             sansformer.0.ff.0.bias            |    512     |\n",
            "|            sansformer.0.ff.3.weight           |   65536    |\n",
            "|             sansformer.0.ff.3.bias            |    128     |\n",
            "|                bin_fc.0.weight                |    128     |\n",
            "|                 bin_fc.0.bias                 |    128     |\n",
            "|                bin_fc.1.weight                |    128     |\n",
            "|                 bin_fc.1.bias                 |     1      |\n",
            "+-----------------------------------------------+------------+\n",
            "Total Trainable Params: 592969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 405: train loss 0.31908 lr 3.980951e-04: 100%|██████████| 406/406 [02:49<00:00,  2.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 1  | loss: 0.68805 | bin_loss: 0.68805 | los_loss: 0.00000\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation epoch: 1  | loss: 0.67060 | bin_loss: 0.67060 | los_loss: 0.00000 | auc_bin: 0.53648 | spearman_los: nan\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2 iter 405: train loss 0.74877 lr 5.067175e-04: 100%|██████████| 406/406 [02:22<00:00,  2.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 2  | loss: 0.68315 | bin_loss: 0.68315 | los_loss: 0.00000\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation epoch: 2  | loss: 0.65949 | bin_loss: 0.65949 | los_loss: 0.00000 | auc_bin: 0.61897 | spearman_los: nan\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 3 iter 405: train loss 0.37460 lr 3.378124e-04: 100%|██████████| 406/406 [02:12<00:00,  3.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 3  | loss: 0.67582 | bin_loss: 0.67582 | los_loss: 0.00000\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation epoch: 3  | loss: 0.65212 | bin_loss: 0.65212 | los_loss: 0.00000 | auc_bin: 0.64917 | spearman_los: nan\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 4 iter 405: train loss 0.33125 lr 1.689074e-04: 100%|██████████| 406/406 [02:10<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 4  | loss: 0.67169 | bin_loss: 0.67169 | los_loss: 0.00000\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation epoch: 4  | loss: 0.64935 | bin_loss: 0.64935 | los_loss: 0.00000 | auc_bin: 0.66206 | spearman_los: nan\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 5 iter 405: train loss 0.38756 lr 2.364680e-09: 100%|██████████| 406/406 [02:22<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 5  | loss: 0.66975 | bin_loss: 0.66975 | los_loss: 0.00000\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation epoch: 5  | loss: 0.64526 | bin_loss: 0.64526 | los_loss: 0.00000 | auc_bin: 0.66590 | spearman_los: nan\n",
            "====================================================================================================\n",
            "Experiment logs stored at: ./experiments/default_addSANS/at_2024_04_14_21_18_55\n",
            "====================================================================================================\n",
            "loaded model from epoch: 4\n",
            "validation epoch: 1  | loss: 0.65201 | bin_loss: 0.65201 | los_loss: 0.00000 | auc_bin: 0.65033 | spearman_los: nan\n",
            "====================================================================================================\n",
            "test epoch: 1  | loss: 0.67490 | bin_loss: 0.67490 | los_loss: 0.00000 | auc_bin: 0.64602 | spearman_los: nan\n",
            "====================================================================================================\n",
            "test epoch: 1  | loss: 0.67490 | bin_loss: 0.67490 | los_loss: 0.00000 | auc_bin: 0.64602 | spearman_los: nan\n",
            "====================================================================================================\n",
            "Done in 14.810524753729503 minutes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x800 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "# import dataset.loaders as loaders\n",
        "# import utils.common as common\n",
        "# from models.mimic_additive_sansformer import MimicAdditiveSansformerModel\n",
        "# from models.mimic_axial_sansformer import MimicAxialSansformerModel\n",
        "# from trainers.mimic_trainer import Trainer_MIMIC\n",
        "\n",
        "MODEL_TYPE = {\n",
        "    \"add_SANSformer\": MimicAdditiveSansformerModel,\n",
        "    \"axial_SANSformer\": MimicAxialSansformerModel,\n",
        "}\n",
        "\n",
        "\n",
        "def run_experiment(cfg, train_dataloader, val_dataloader, test_dataloaders):\n",
        "\n",
        "    assert (\n",
        "        cfg.MODEL.TYPE in MODEL_TYPE.keys()\n",
        "    ), f\"Model type name should be among {MODEL_TYPE.keys()}\"\n",
        "\n",
        "    # define model\n",
        "    model = MODEL_TYPE[cfg.MODEL.TYPE](cfg)\n",
        "    # initialize the trainer\n",
        "    trainer = Trainer_MIMIC(\n",
        "        cfg, model, train_dataloader, val_dataloader, test_dataloaders\n",
        "    )\n",
        "    # fit on training data\n",
        "    trainer.fit()\n",
        "    # predict on valid and test data\n",
        "    test_metrics_l = trainer.predict()\n",
        "\n",
        "    log_test_results_to_csv(\n",
        "        cfg,\n",
        "        './drive/MyDrive/mimic-iv-1.0/results_log.csv',\n",
        "        test_metrics_l,\n",
        "    )\n",
        "\n",
        "\n",
        "def main():\n",
        "    starttime = time.time()\n",
        "    # Parse cmd line args\n",
        "    args = parse_args()\n",
        "    cfg = handle_config_and_log_paths(args)\n",
        "    # set experiment seed\n",
        "    seed_everything(cfg.RNG_SEED)\n",
        "\n",
        "    (\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        test_dataloaders,\n",
        "    ) = get_mimic_dataloaders(cfg)\n",
        "\n",
        "    cfg.defrost()\n",
        "\n",
        "    cfg.OPTIM.STEPS_PER_EPOCH = len(train_dataloader) // cfg.MODEL.ACCU_GRAD_STEPS\n",
        "    print(f\"Number of steps per epoch: {len(train_dataloader)}\")\n",
        "\n",
        "    cfg.MODEL.VOCAB_SIZE = train_dataloader.dataset.vectorizer.seq_vocab_len\n",
        "    print(f\"Total vocab size: {train_dataloader.dataset.vectorizer.seq_vocab_len}\")\n",
        "\n",
        "    cfg.freeze()\n",
        "\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"Running Experiment: {cfg.PATHS.EXPERIMENT_NAME}\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    # run experiment\n",
        "    run_experiment(cfg, train_dataloader, val_dataloader, test_dataloaders)\n",
        "\n",
        "    print(f\"Done in {(time.time() - starttime)/60} minutes.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    sys.argv = ['script_name', '--cfg', './drive/MyDrive/mimic-iv-1.0/config_additive_sansformer_test.yml']\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "# Model comparison\n",
        "  * As shown in the results displayed, specifically the auc_bin value, we can see that our model is being outperformed by all of the models that the authors are comparing sansformers to. However, there is room for improvement on our end.\n",
        "\n",
        "  ![Model Comparison](https://drive.google.com/uc?export=view&id=1WyxfmGBbm5vT4QYtnD0vIigVzeFEUguv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a09c364-9bf6-4af5-b6f8-4b54c8e37f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.674900051411681, bin_loss: 0.674900051411681, los_loss: 0.0, auc_bin: 0.646023880791255, spearman_los: nan, base_lr: 0.00059117, lr_policy: 1cycle, batch_size: 32, optim_momentum: 0.9, max_seq_length: 100, embed_size: 128, max_epochs: 5, exp_dir: ./experiments/default_addSANS/at_2024_04_14_21_18_55, exp_name: default_addSANS, test_id: 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/mimic-iv-1.0/results_log.csv')\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    loss = row['loss']\n",
        "    bin_loss = row['bin_loss']\n",
        "    los_loss = row['los_loss']\n",
        "    auc_bin = row['auc_bin']\n",
        "    spearman_los = row['spearman_los']\n",
        "    base_lr = row['base_lr']\n",
        "    lr_policy = row['lr_policy']\n",
        "    batch_size = row['batch_size']\n",
        "    optim_momentum = row['optim_momentum']\n",
        "    max_seq_length = row['max_seq_length']\n",
        "    embed_size = row['embed_size']\n",
        "    max_epochs = row['max_epochs']\n",
        "    exp_dir = row['exp_dir']\n",
        "    exp_name = row['exp_name']\n",
        "    test_id = row['test_id']\n",
        "\n",
        "    print(f\"Loss: {loss}, bin_loss: {bin_loss}, los_loss: {los_loss}, auc_bin: {auc_bin}, spearman_los: {spearman_los}, base_lr: {base_lr}, lr_policy: {lr_policy}, batch_size: {batch_size}, optim_momentum: {optim_momentum}, max_seq_length: {max_seq_length}, embed_size: {embed_size}, max_epochs: {max_epochs}, exp_dir: {exp_dir}, exp_name: {exp_name}, test_id: {test_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "* **Reproducibility Assessment**: The paper is currently not reproducible since our results are not on par with those reported in the paper. In the Model Comparison section, our AUC result falls short compared to the other models evaluated by the authors. However, it's worth noting that we applied data sampling and modified configurations to reduce runtime, which might have affected our results.\n",
        "\n",
        "* **Ease and Difficulty in Reproduction**: The easiest part of the reproduction process was leveraging the provided code from the paper's authors. However, a significant challenge arose due to missing code for the vectorizer. We had to collaborate with another group to obtain and save the missing vectorizer. This hurdle significantly delayed our progress in successfully running the training code on the model.\n",
        "\n",
        "* **Suggestions for Improvement**: To enhance reproducibility, the authors could improve code readability by adding more comments and organizing it more efficiently. Additionally, providing the missing vectorizer code from the data preprocessing step would have been beneficial for reproducers. Clear documentation of dependencies and environment setup instructions would also facilitate easier reproduction.\n",
        "\n",
        "* **Next Steps**: In the next phase, we aim to enhance the organization of our code and eliminate any Pummel-related processing and metrics. We also plan to perform training and evaluation on the other sansformers model, MIMIC Axial Sansformer. Furthermore, we plan to optimize the training process by training the model separately and loading it onto the notebook later. This strategy aims to reduce runtime, which is currently approximately 18 minutes for the entire notebook execution. Additionally, we intend to continue experimenting with different parameters to improve results while minimizing training and testing time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1. Y. Kumar, A. Ilin, H. Salo, S. Kulathinal, M. K. Leinonen and P. Marttinen, \"Self-Supervised Forecasting in Electronic Health Records with Attention-Free Models,\" in IEEE Transactions on Artificial Intelligence, doi: 10.1109/TAI.2024.3353164.\n",
        "keywords: {Medical services;Transformers;Data models;Predictive models;Computational modeling;Biological system modeling;Task analysis;Deep Learning;Electronic Health Records;Healthcare;Healthcare Utilization;Transfer Learning;Transformers},\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64e057af44e046609cb09790419248c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b51bf74fc2a74e2b84126c9509b1a22d",
              "IPY_MODEL_7948725cd9d040b9bda6e89408c1ad00",
              "IPY_MODEL_067346f6ad584f82a109f8c5665c1b92"
            ],
            "layout": "IPY_MODEL_5cf2d7ec6ab840ebad3e577c13334cd5"
          }
        },
        "b51bf74fc2a74e2b84126c9509b1a22d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d113e9e39de74bb39d0de1514e533277",
            "placeholder": "​",
            "style": "IPY_MODEL_4accf68eb03542a88fba1146c06b20b4",
            "value": "100%"
          }
        },
        "7948725cd9d040b9bda6e89408c1ad00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce203165eec497eb8269d11780ea1ab",
            "max": 449784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5fb89f8d731470aafdc3ff0e9e792d6",
            "value": 449784
          }
        },
        "067346f6ad584f82a109f8c5665c1b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bb66177bf94d82b55efb12a008c2b3",
            "placeholder": "​",
            "style": "IPY_MODEL_5e6f39f20c2a495e972205666bc9e548",
            "value": " 449784/449784 [01:18&lt;00:00, 3353.91it/s]"
          }
        },
        "5cf2d7ec6ab840ebad3e577c13334cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d113e9e39de74bb39d0de1514e533277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4accf68eb03542a88fba1146c06b20b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce203165eec497eb8269d11780ea1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5fb89f8d731470aafdc3ff0e9e792d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44bb66177bf94d82b55efb12a008c2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e6f39f20c2a495e972205666bc9e548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "846a30cb7f23402fa724c24b2189c402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88cb8b19156c4c378f47da211f2d23f3",
              "IPY_MODEL_d39f121641c64af79e5cb27757d7d5b5",
              "IPY_MODEL_28a40763bcb84a3fa6c507520c40e72c"
            ],
            "layout": "IPY_MODEL_356726fe5802402487e8c7ead670b8bd"
          }
        },
        "88cb8b19156c4c378f47da211f2d23f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b3324c17eb47a58c27b7cf7b792b6f",
            "placeholder": "​",
            "style": "IPY_MODEL_38784163c32f4f9482dca580424d6866",
            "value": "100%"
          }
        },
        "d39f121641c64af79e5cb27757d7d5b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ec3204f33d4f01bacb05ce4da77730",
            "max": 148327,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_686a07c81a2b4966825679b4c57f9f63",
            "value": 148327
          }
        },
        "28a40763bcb84a3fa6c507520c40e72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a848be062842a98b509b9fdc283562",
            "placeholder": "​",
            "style": "IPY_MODEL_c9e7e4ca8e0d4d80b7d5908ee2f36d4d",
            "value": " 148327/148327 [00:22&lt;00:00, 7807.36it/s]"
          }
        },
        "356726fe5802402487e8c7ead670b8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44b3324c17eb47a58c27b7cf7b792b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38784163c32f4f9482dca580424d6866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2ec3204f33d4f01bacb05ce4da77730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686a07c81a2b4966825679b4c57f9f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27a848be062842a98b509b9fdc283562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9e7e4ca8e0d4d80b7d5908ee2f36d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a087633887b4e63aaf63a6e5529a56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5dcdbc6f610c4e7889cd4b7ec824c272",
              "IPY_MODEL_09f6da86b76a4cde863889cce65220f3",
              "IPY_MODEL_39845296b6bb47af9a95befe5f9218b8"
            ],
            "layout": "IPY_MODEL_0eb5d30431a24cddb49b11bdcd2bcb1e"
          }
        },
        "5dcdbc6f610c4e7889cd4b7ec824c272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847af178dae4485d8e76f99ac4b681aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f1dc613adae44afd9f0b0ac739dc5fb8",
            "value": "100%"
          }
        },
        "09f6da86b76a4cde863889cce65220f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229712339d644ddfb6d4b5b5e4da46a7",
            "max": 197162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27418d8a0ec844868c7d4e63f251cabd",
            "value": 197162
          }
        },
        "39845296b6bb47af9a95befe5f9218b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa1cfa586a5b488c8819484f13b62f5b",
            "placeholder": "​",
            "style": "IPY_MODEL_e1a7bbe543a74fbc94df21d4fb9dae50",
            "value": " 197162/197162 [00:24&lt;00:00, 7800.76it/s]"
          }
        },
        "0eb5d30431a24cddb49b11bdcd2bcb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847af178dae4485d8e76f99ac4b681aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1dc613adae44afd9f0b0ac739dc5fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229712339d644ddfb6d4b5b5e4da46a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27418d8a0ec844868c7d4e63f251cabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa1cfa586a5b488c8819484f13b62f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a7bbe543a74fbc94df21d4fb9dae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c964093ec0434f3db65043939bc9a152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1db7f588a2145d088c093426a13cbda",
              "IPY_MODEL_ccf976d0fd9345649cd1d860dd6fb570",
              "IPY_MODEL_490a6098099d4ce1a59e0a128ba82181"
            ],
            "layout": "IPY_MODEL_c7fe6600b2a64d0db611029b2bf40d45"
          }
        },
        "b1db7f588a2145d088c093426a13cbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03803fbfbea549db8f2e353cee146751",
            "placeholder": "​",
            "style": "IPY_MODEL_788c5177416c424692b4905e36c5ec3c",
            "value": "100%"
          }
        },
        "ccf976d0fd9345649cd1d860dd6fb570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2add81473a3744b3b6d7c4dd50700dff",
            "max": 164844,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e02f4b8bfa04b9a91a6bb6ce04aea3f",
            "value": 164844
          }
        },
        "490a6098099d4ce1a59e0a128ba82181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5218d9bc89634e979f96fb128052a2af",
            "placeholder": "​",
            "style": "IPY_MODEL_3b6a680bf5054c9ea39e068f9ccb0132",
            "value": " 164844/164844 [00:22&lt;00:00, 6564.87it/s]"
          }
        },
        "c7fe6600b2a64d0db611029b2bf40d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03803fbfbea549db8f2e353cee146751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788c5177416c424692b4905e36c5ec3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2add81473a3744b3b6d7c4dd50700dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e02f4b8bfa04b9a91a6bb6ce04aea3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5218d9bc89634e979f96fb128052a2af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b6a680bf5054c9ea39e068f9ccb0132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc9428ac629f4de0ac6c5a0cf3f5f1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a78d2da600c84d88bcce3e437b9c7144",
              "IPY_MODEL_0ed75e1301664f01bba7627a21a8112a",
              "IPY_MODEL_69169a172b6e4729aab4aedce6ac589c"
            ],
            "layout": "IPY_MODEL_c8c115d4844144fd8ad5c6f3a67a3081"
          }
        },
        "a78d2da600c84d88bcce3e437b9c7144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02103f42edfd4ef1875b442a7a20e88d",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd05ddbbb7e4434b8413b9975e0ba29",
            "value": "100%"
          }
        },
        "0ed75e1301664f01bba7627a21a8112a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00a9a5bd0d2341c88106fd92ff1560e2",
            "max": 9978,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76388ba2432e440594ac907d3849ccbe",
            "value": 9978
          }
        },
        "69169a172b6e4729aab4aedce6ac589c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f032b847bc3a4109b3f3cd3937da6c15",
            "placeholder": "​",
            "style": "IPY_MODEL_104eefed747940e8b99d193f0ada60a3",
            "value": " 9978/9978 [00:09&lt;00:00, 1405.18it/s]"
          }
        },
        "c8c115d4844144fd8ad5c6f3a67a3081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02103f42edfd4ef1875b442a7a20e88d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cd05ddbbb7e4434b8413b9975e0ba29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00a9a5bd0d2341c88106fd92ff1560e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76388ba2432e440594ac907d3849ccbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f032b847bc3a4109b3f3cd3937da6c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104eefed747940e8b99d193f0ada60a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}